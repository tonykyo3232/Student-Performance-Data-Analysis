{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7127cb0",
   "metadata": {},
   "source": [
    "### Read the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd5286f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Student Performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e8973",
   "metadata": {},
   "source": [
    "### KNN Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a393d",
   "metadata": {},
   "source": [
    "<img src=\"Model 1.jpg\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4444b3",
   "metadata": {},
   "source": [
    "### Obtain the feature matrix and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe636c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix\n",
      "[[0.72 0.72 0.74]\n",
      " [0.69 0.9  0.88]\n",
      " [0.9  0.95 0.93]\n",
      " ...\n",
      " [0.59 0.71 0.65]\n",
      " [0.68 0.78 0.77]\n",
      " [0.77 0.86 0.86]]\n",
      "size: (1000, 3)\n",
      "\n",
      "Labels\n",
      "[1 2 1 0 2 1 1 1 3 1 2 3 1 0 0 2 2 1 2 2 3 1 3 2 3 0 1 2 2 3 3 1 4 3 4 4 3\n",
      " 3 3 1 2 2 1 1 4 1 0 2 3 2 4 4 2 3 2 2 4 3 3 2 4 0 0 2 3 1 3 2 1 2 3 3 0 2\n",
      " 2 1 4 0 3 4 1 1 0 4 3 2 2 3 0 3 2 2 2 2 1 2 1 4 3 3 1 3 3 1 2 2 3 4 1 1 3\n",
      " 2 0 3 4 2 1 3 3 2 2 1 2 3 4 1 1 3 3 0 3 2 4 2 3 2 1 4 2 3 3 2 4 0 3 2 1 2\n",
      " 3 4 0 0 1 3 3 2 4 1 1 3 1 4 1 2 4 2 2 1 1 2 0 4 3 2 2 2 1 2 1 3 2 2 4 3 2\n",
      " 2 4 3 1 2 4 3 1 3 2 3 2 4 1 1 2 3 2 1 2 3 4 4 1 1 3 2 2 2 4 1 4 2 1 1 3 1\n",
      " 2 3 1 4 2 3 0 2 3 2 1 4 2 3 3 3 1 2 3 4 3 4 3 2 4 1 1 2 0 3 1 3 3 4 2 2 1\n",
      " 2 2 2 2 4 3 3 2 3 3 4 2 2 3 3 1 2 2 4 2 1 3 3 3 3 1 1 4 1 1 4 2 3 2 4 3 1\n",
      " 0 4 2 3 0 3 2 1 2 0 4 2 1 3 1 1 3 2 2 2 3 2 1 3 2 4 2 2 2 2 2 0 2 1 2 2 4\n",
      " 1 2 1 3 2 1 3 2 2 1 3 3 2 1 2 3 4 1 4 2 2 2 1 0 2 3 3 1 1 2 3 2 0 2 2 0 3\n",
      " 4 2 3 3 3 4 3 3 0 0 1 2 2 4 0 4 4 2 3 3 4 3 4 2 2 0 1 2 1 3 2 0 0 3 2 2 1\n",
      " 1 3 3 3 4 3 1 2 4 2 2 3 4 2 3 3 0 1 2 2 2 0 2 2 2 2 0 2 2 3 3 2 3 2 3 0 1\n",
      " 0 2 3 2 1 1 2 4 2 2 2 2 3 3 4 1 2 1 4 2 0 2 3 0 0 2 2 2 2 3 1 3 4 3 3 4 1\n",
      " 3 2 0 1 2 3 2 1 0 0 2 2 2 1 3 2 3 1 4 3 1 2 4 3 1 0 1 2 2 3 0 3 1 1 2 3 4\n",
      " 3 1 3 2 3 2 2 4 2 2 3 2 2 2 4 4 1 2 2 3 4 0 2 3 2 3 3 4 0 2 2 2 2 1 1 3 4\n",
      " 2 2 2 1 3 3 2 2 3 1 1 4 3 1 3 1 0 2 2 4 0 0 1 1 3 3 4 3 3 3 2 0 2 2 0 2 0\n",
      " 4 4 2 2 1 0 3 3 3 2 4 3 3 2 2 2 4 1 3 2 2 2 0 2 4 3 3 2 2 1 2 0 4 3 1 3 3\n",
      " 2 3 1 1 2 3 0 1 3 4 3 3 3 1 4 1 1 3 4 1 3 2 0 3 0 1 1 2 3 3 3 2 2 3 2 3 2\n",
      " 2 1 2 3 2 3 2 2 3 1 4 2 3 3 3 1 1 2 1 4 4 3 0 4 2 4 2 3 2 3 2 0 3 2 4 1 0\n",
      " 3 1 0 3 2 3 3 2 4 3 3 1 1 2 2 2 4 2 3 1 2 1 4 4 4 3 2 1 0 2 3 4 2 2 1 3 2\n",
      " 3 0 2 2 1 3 3 2 2 1 3 4 2 2 2 4 3 4 3 1 2 3 3 1 3 1 2 1 3 0 1 3 1 2 1 1 1\n",
      " 2 0 4 3 1 1 2 2 1 4 1 2 2 1 3 3 4 1 4 3 4 4 2 2 2 4 1 2 0 3 4 2 1 0 0 2 4\n",
      " 2 1 0 3 1 2 0 3 4 1 2 2 2 2 3 1 0 2 0 1 1 2 4 0 1 2 3 2 1 1 3 4 2 3 2 3 2\n",
      " 0 4 4 2 1 1 2 1 2 2 4 3 2 2 3 2 1 4 2 1 2 1 4 2 2 3 2 3 3 2 4 1 3 4 2 4 2\n",
      " 3 3 4 4 0 3 4 4 1 1 3 3 3 2 0 3 3 3 1 3 2 4 3 0 2 2 1 4 4 2 2 1 3 2 3 1 3\n",
      " 4 4 3 4 2 2 3 3 2 2 3 0 4 3 3 2 3 2 0 1 2 1 3 1 4 4 3 4 2 2 4 2 3 3 2 0 3\n",
      " 4 2 3 3 0 2 4 1 3 2 0 3 0 2 1 2 3 2 1 3 1 0 2 0 2 4 0 3 4 1 3 3 0 4 2 2 3\n",
      " 3]\n",
      "size: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# convert these data into 2D numpy array\n",
    "# order: math percentage, reading score percentage, writing score percentage\n",
    "X = np.array([[df['math percentage'][0], \n",
    "              df['reading score percentage'][0], \n",
    "              df['writing score percentage'][0]]], \n",
    "             dtype = 'float')\n",
    "for i in range(1,1000):\n",
    "    X = np.append(X, [[df['math percentage'][i], \n",
    "                  df['reading score percentage'][i], \n",
    "                  df['writing score percentage'][i]]],axis=0)\n",
    "print('feature matrix')\n",
    "print(X)\n",
    "print('size: ' + str(X.shape))\n",
    "print()\n",
    "\n",
    "# Group A to Group E labeled as 0,1,2,3,4\n",
    "if(df['race/ethnicity'][0] == 'group A'):\n",
    "    first_elem = 0\n",
    "elif(df['race/ethnicity'][0] == 'group B'):\n",
    "    first_elem = 1\n",
    "elif(df['race/ethnicity'][0] == 'group C'):\n",
    "    first_elem = 2\n",
    "elif(df['race/ethnicity'][0] == 'group D'):\n",
    "    first_elem = 3\n",
    "else:\n",
    "    first_elem = 4\n",
    "    \n",
    "y = np.array([first_elem], dtype = 'int')\n",
    "for i in range(1,1000):\n",
    "    if(df['race/ethnicity'][i] == 'group A'):\n",
    "        y = np.append(y, 0)\n",
    "    elif(df['race/ethnicity'][i] == 'group B'):\n",
    "        y = np.append(y, 1)\n",
    "    elif(df['race/ethnicity'][i] == 'group C'):\n",
    "        y = np.append(y, 2)\n",
    "    elif(df['race/ethnicity'][i] == 'group D'):\n",
    "        y = np.append(y, 3)\n",
    "    else:\n",
    "        y = np.append(y, 4)\n",
    "print('Labels')\n",
    "print(y)\n",
    "print('size: ' + str(y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3500e6",
   "metadata": {},
   "source": [
    "Using KNN to do the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e64dfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following line, \"knn\" is instantiated as an \"object\" of 'KNeighborsClassifier' \"class\". \n",
    "# most of the time we use default k value\n",
    "k = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580642ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the method \"fit\" of the \"object knn\" along with training dataset and labels to train the model.\n",
    "# where:\n",
    "# X = iris.data  # X will be 'feature matrix'\n",
    "# y = iris.target  # y will be 'label vector'\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6536918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "# X: feature, Y: label\n",
    "X_Testing = [[0.72,0.72,0.74]]\n",
    "y_predict = knn.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e6ca238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "# Two new data samples:\n",
    "# if there are 2 new flowers and want to detect both of them\n",
    "# [0, 1, 2] => ['setosa' 'versicolor' 'virginica']\n",
    "X_Testing = [[0.72,0.72,0.74],[0.69,0.9,0.88]]\n",
    "y_predict = knn.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfb0ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# where X is all the sample data, y is all the labels\n",
    "# random_state=1 means only random once and rest stay the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6) # We can fix the random_state for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "913bcbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 3)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "573a908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7282a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55 0.41 0.48]\n",
      " [0.44 0.54 0.53]\n",
      " [0.7  0.64 0.7 ]\n",
      " [0.6  0.59 0.54]\n",
      " [0.7  0.56 0.51]\n",
      " [0.92 0.79 0.84]\n",
      " [0.64 0.79 0.77]\n",
      " [0.86 0.81 0.75]\n",
      " [0.99 0.93 0.9 ]\n",
      " [0.78 0.77 0.77]\n",
      " [0.73 0.76 0.78]\n",
      " [0.33 0.41 0.43]\n",
      " [0.69 0.58 0.53]\n",
      " [0.65 0.78 0.82]\n",
      " [0.45 0.59 0.64]\n",
      " [0.59 0.65 0.66]\n",
      " [0.97 0.92 0.86]\n",
      " [0.57 0.69 0.68]\n",
      " [0.81 0.8  0.76]\n",
      " [0.63 0.6  0.57]\n",
      " [0.54 0.59 0.5 ]\n",
      " [0.62 0.67 0.69]\n",
      " [0.64 0.66 0.59]\n",
      " [0.81 0.72 0.77]\n",
      " [0.73 0.76 0.78]\n",
      " [0.36 0.29 0.27]\n",
      " [0.58 0.61 0.52]\n",
      " [0.5  0.48 0.53]\n",
      " [0.81 0.88 0.9 ]\n",
      " [0.62 0.68 0.68]\n",
      " [0.68 0.54 0.53]\n",
      " [0.53 0.71 0.67]\n",
      " [0.18 0.32 0.28]\n",
      " [0.69 0.58 0.57]\n",
      " [0.4  0.52 0.43]\n",
      " [0.63 0.55 0.63]\n",
      " [0.66 0.63 0.64]\n",
      " [0.65 0.7  0.71]\n",
      " [0.66 0.65 0.6 ]\n",
      " [0.61 0.47 0.56]\n",
      " [0.43 0.62 0.61]\n",
      " [0.5  0.48 0.42]\n",
      " [0.82 0.85 0.87]\n",
      " [0.6  0.7  0.74]\n",
      " [0.87 0.73 0.72]\n",
      " [0.82 0.85 0.86]\n",
      " [0.88 0.99 0.95]\n",
      " [0.64 0.73 0.68]\n",
      " [0.69 0.65 0.74]\n",
      " [0.66 0.72 0.7 ]\n",
      " [0.37 0.45 0.38]\n",
      " [0.52 0.57 0.56]\n",
      " [0.87 0.84 0.76]\n",
      " [0.52 0.7  0.62]\n",
      " [0.79 0.73 0.67]\n",
      " [0.78 0.82 0.79]\n",
      " [0.67 0.75 0.7 ]\n",
      " [0.7  0.89 0.88]\n",
      " [0.54 0.48 0.52]\n",
      " [0.68 0.75 0.81]\n",
      " [0.67 0.76 0.75]\n",
      " [0.67 0.54 0.63]\n",
      " [0.65 0.74 0.77]\n",
      " [0.46 0.43 0.42]\n",
      " [0.5  0.5  0.47]\n",
      " [0.69 0.75 0.78]\n",
      " [0.54 0.54 0.45]\n",
      " [0.66 0.65 0.69]\n",
      " [0.85 0.86 0.98]\n",
      " [0.58 0.57 0.54]\n",
      " [0.82 0.78 0.74]\n",
      " [0.46 0.56 0.57]\n",
      " [0.73 0.67 0.59]\n",
      " [0.74 0.79 0.75]\n",
      " [0.59 0.54 0.67]\n",
      " [0.75 0.77 0.83]\n",
      " [0.85 0.75 0.68]\n",
      " [0.29 0.4  0.44]\n",
      " [0.97 1.   1.  ]\n",
      " [0.81 0.78 0.78]\n",
      " [0.4  0.42 0.38]\n",
      " [0.76 0.78 0.75]\n",
      " [0.54 0.63 0.67]\n",
      " [0.75 0.68 0.65]\n",
      " [0.3  0.24 0.15]\n",
      " [0.69 0.86 0.81]\n",
      " [0.87 0.84 0.85]\n",
      " [0.46 0.64 0.66]\n",
      " [0.62 0.66 0.68]\n",
      " [0.44 0.64 0.58]\n",
      " [0.65 0.64 0.62]\n",
      " [0.48 0.56 0.58]\n",
      " [0.58 0.67 0.72]\n",
      " [0.7  0.64 0.72]\n",
      " [0.35 0.53 0.46]\n",
      " [0.66 0.74 0.78]\n",
      " [0.81 0.75 0.78]\n",
      " [0.74 0.79 0.8 ]\n",
      " [0.74 0.64 0.6 ]\n",
      " [0.47 0.37 0.35]\n",
      " [0.81 0.77 0.79]\n",
      " [0.81 0.91 0.89]\n",
      " [0.72 0.65 0.68]\n",
      " [0.4  0.58 0.54]\n",
      " [0.71 0.66 0.65]\n",
      " [0.88 0.99 1.  ]\n",
      " [0.83 0.85 0.9 ]\n",
      " [0.74 0.71 0.78]\n",
      " [0.77 0.88 0.85]\n",
      " [0.42 0.66 0.69]\n",
      " [0.67 0.84 0.81]\n",
      " [0.69 0.77 0.78]\n",
      " [0.65 0.81 0.73]\n",
      " [0.69 0.79 0.81]\n",
      " [0.63 0.48 0.47]\n",
      " [0.55 0.61 0.54]\n",
      " [0.59 0.53 0.52]\n",
      " [0.58 0.67 0.62]\n",
      " [0.6  0.68 0.6 ]\n",
      " [0.78 0.79 0.76]\n",
      " [0.73 0.78 0.72]\n",
      " [0.9  0.95 0.93]\n",
      " [0.   0.17 0.1 ]\n",
      " [0.91 0.95 0.94]\n",
      " [0.79 0.89 0.86]\n",
      " [0.72 0.81 0.79]\n",
      " [0.63 0.69 0.74]\n",
      " [0.62 0.49 0.52]\n",
      " [0.76 0.72 0.71]\n",
      " [0.92 1.   1.  ]\n",
      " [0.64 0.53 0.57]\n",
      " [0.43 0.45 0.5 ]\n",
      " [0.5  0.67 0.73]\n",
      " [0.68 0.86 0.84]\n",
      " [0.77 0.82 0.89]\n",
      " [0.48 0.58 0.52]\n",
      " [0.72 0.72 0.74]\n",
      " [0.65 0.81 0.77]\n",
      " [0.63 0.63 0.62]\n",
      " [0.66 0.76 0.68]\n",
      " [0.75 0.84 0.8 ]\n",
      " [0.75 0.74 0.66]\n",
      " [0.68 0.8  0.76]\n",
      " [0.82 0.82 0.8 ]\n",
      " [0.73 0.68 0.66]\n",
      " [0.53 0.52 0.49]\n",
      " [0.67 0.81 0.79]\n",
      " [0.64 0.5  0.43]\n",
      " [0.77 0.79 0.8 ]\n",
      " [0.7  0.7  0.7 ]\n",
      " [0.55 0.72 0.79]\n",
      " [0.53 0.62 0.53]\n",
      " [0.49 0.53 0.52]\n",
      " [0.35 0.44 0.43]\n",
      " [0.9  0.87 0.75]\n",
      " [0.49 0.57 0.46]\n",
      " [0.51 0.54 0.41]\n",
      " [0.55 0.64 0.7 ]\n",
      " [0.52 0.59 0.56]\n",
      " [0.62 0.64 0.55]\n",
      " [1.   1.   1.  ]\n",
      " [0.85 0.84 0.78]\n",
      " [0.59 0.72 0.8 ]\n",
      " [0.93 0.9  0.83]\n",
      " [0.61 0.67 0.66]\n",
      " [0.59 0.69 0.65]\n",
      " [0.84 0.87 0.91]\n",
      " [0.77 0.82 0.91]\n",
      " [0.46 0.43 0.44]\n",
      " [0.62 0.63 0.56]\n",
      " [0.82 0.82 0.88]\n",
      " [0.59 0.51 0.43]\n",
      " [0.75 0.69 0.68]\n",
      " [0.61 0.7  0.76]\n",
      " [0.6  0.72 0.68]\n",
      " [0.46 0.43 0.41]\n",
      " [0.9  0.85 0.84]\n",
      " [0.52 0.59 0.65]\n",
      " [0.82 0.93 0.93]\n",
      " [0.73 0.83 0.76]\n",
      " [0.59 0.73 0.72]\n",
      " [0.72 0.66 0.66]\n",
      " [0.59 0.78 0.76]\n",
      " [0.67 0.86 0.83]\n",
      " [0.34 0.48 0.41]\n",
      " [0.45 0.56 0.54]\n",
      " [0.6  0.68 0.72]\n",
      " [0.8  0.9  0.82]\n",
      " [0.96 0.9  0.92]\n",
      " [0.88 0.75 0.76]\n",
      " [0.49 0.52 0.51]\n",
      " [0.52 0.67 0.72]\n",
      " [0.79 0.81 0.82]\n",
      " [0.5  0.64 0.59]\n",
      " [0.23 0.44 0.36]\n",
      " [0.61 0.51 0.52]\n",
      " [0.62 0.55 0.55]\n",
      " [0.51 0.31 0.36]\n",
      " [0.59 0.7  0.66]\n",
      " [0.64 0.6  0.58]\n",
      " [0.75 0.73 0.74]\n",
      " [0.85 0.81 0.85]\n",
      " [0.86 0.8  0.75]\n",
      " [0.71 0.83 0.77]\n",
      " [0.58 0.7  0.67]\n",
      " [0.54 0.49 0.47]\n",
      " [0.4  0.65 0.64]\n",
      " [0.58 0.75 0.77]\n",
      " [0.27 0.34 0.36]\n",
      " [0.67 0.74 0.77]\n",
      " [0.62 0.65 0.58]\n",
      " [0.42 0.52 0.51]\n",
      " [0.76 0.87 0.85]\n",
      " [0.67 0.89 0.82]\n",
      " [0.62 0.74 0.7 ]\n",
      " [0.62 0.56 0.53]\n",
      " [0.65 0.77 0.74]\n",
      " [0.49 0.63 0.56]\n",
      " [0.63 0.61 0.54]\n",
      " [0.47 0.54 0.53]\n",
      " [0.64 0.62 0.68]\n",
      " [0.46 0.61 0.55]\n",
      " [0.53 0.44 0.42]\n",
      " [0.61 0.55 0.52]\n",
      " [0.81 0.84 0.82]\n",
      " [0.55 0.47 0.44]\n",
      " [0.55 0.76 0.76]\n",
      " [0.84 0.8  0.8 ]\n",
      " [0.5  0.53 0.55]\n",
      " [0.53 0.7  0.7 ]\n",
      " [0.88 0.77 0.77]\n",
      " [0.71 0.7  0.76]\n",
      " [0.89 0.88 0.82]\n",
      " [0.61 0.86 0.87]\n",
      " [0.63 0.61 0.61]\n",
      " [0.49 0.58 0.6 ]\n",
      " [0.45 0.73 0.7 ]\n",
      " [0.73 0.75 0.8 ]\n",
      " [0.8  0.79 0.79]\n",
      " [0.35 0.61 0.54]\n",
      " [0.62 0.7  0.72]\n",
      " [0.61 0.6  0.57]\n",
      " [0.78 0.72 0.7 ]\n",
      " [0.58 0.54 0.52]\n",
      " [0.7  0.55 0.56]\n",
      " [0.48 0.45 0.41]\n",
      " [0.8  0.9  0.89]\n",
      " [0.66 0.59 0.52]\n",
      " [0.79 0.82 0.73]\n",
      " [0.74 0.9  0.88]\n",
      " [0.71 0.79 0.71]\n",
      " [0.69 0.6  0.63]\n",
      " [0.82 0.8  0.77]\n",
      " [0.61 0.42 0.41]\n",
      " [0.75 0.82 0.9 ]\n",
      " [0.87 0.74 0.7 ]\n",
      " [0.74 0.74 0.72]\n",
      " [0.56 0.72 0.65]\n",
      " [0.68 0.68 0.61]\n",
      " [0.8  0.85 0.85]\n",
      " [0.57 0.78 0.67]\n",
      " [0.58 0.62 0.59]\n",
      " [0.84 0.83 0.75]\n",
      " [0.63 0.73 0.68]\n",
      " [0.68 0.51 0.57]\n",
      " [0.27 0.34 0.32]\n",
      " [0.59 0.63 0.64]\n",
      " [0.69 0.7  0.67]\n",
      " [0.88 0.93 0.93]\n",
      " [0.84 0.77 0.74]\n",
      " [0.56 0.79 0.72]\n",
      " [0.73 0.74 0.72]\n",
      " [0.76 0.71 0.73]\n",
      " [0.76 0.78 0.8 ]\n",
      " [0.69 0.71 0.65]\n",
      " [0.57 0.61 0.54]\n",
      " [0.59 0.58 0.47]\n",
      " [0.66 0.74 0.73]\n",
      " [0.59 0.62 0.64]\n",
      " [0.48 0.52 0.45]\n",
      " [0.87 1.   0.95]\n",
      " [0.55 0.46 0.44]\n",
      " [0.63 0.75 0.81]\n",
      " [0.86 0.73 0.7 ]\n",
      " [0.61 0.56 0.55]\n",
      " [0.87 1.   1.  ]\n",
      " [0.62 0.55 0.54]\n",
      " [0.91 0.89 0.92]\n",
      " [0.77 0.69 0.68]\n",
      " [0.63 0.78 0.79]\n",
      " [0.62 0.62 0.63]\n",
      " [0.74 0.63 0.57]\n",
      " [0.82 0.75 0.77]\n",
      " [0.6  0.44 0.47]\n",
      " [0.56 0.52 0.55]\n",
      " [0.97 0.97 0.96]\n",
      " [0.61 0.58 0.62]\n",
      " [0.59 0.63 0.75]\n",
      " [0.83 0.83 0.9 ]\n",
      " [0.7  0.72 0.76]]\n",
      "\n",
      "\n",
      "[3 3 4 3 2 2 2 4 4 2 4 2 2 3 0 1 0 1 4 2 2 0 2 3 2 1 2 2 2 4 1 1 1 3 3 3 4\n",
      " 3 1 3 2 2 1 1 2 4 4 2 3 1 4 3 4 1 3 3 2 2 2 3 4 3 2 2 4 2 1 4 3 2 1 3 4 3\n",
      " 2 3 4 2 3 3 3 2 0 1 1 3 3 2 3 0 1 1 2 1 2 4 3 4 4 2 2 1 1 2 2 3 2 3 0 2 2\n",
      " 3 1 3 1 2 2 3 1 1 2 1 2 2 3 1 2 3 3 4 1 2 0 2 1 2 1 3 0 2 1 3 0 1 3 2 2 0\n",
      " 4 3 2 2 1 2 3 3 1 3 3 2 4 1 3 4 2 2 2 3 4 1 3 4 2 3 1 4 4 3 2 1 2 3 3 1 0\n",
      " 4 2 3 2 1 4 1 4 3 1 0 2 0 1 0 3 3 3 0 0 3 3 2 2 2 2 1 2 1 2 4 2 2 2 2 4 1\n",
      " 2 3 2 3 3 2 1 1 3 4 3 1 0 3 2 3 3 2 3 0 0 2 4 0 3 2 0 1 2 3 1 1 2 4 4 4 2\n",
      " 4 2 1 1 2 4 3 1 3 2 2 2 0 3 4 2 2 1 4 2 1 2 3 2 3 2 3 1 1 4 1 1 1 2 1 3 1\n",
      " 4 4 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15df71fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8a0c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 2 0 3 3 1 2 4 3 2 0 2 3 2 0 1 3 1 3 1 2 2 3 2 1 0 3 2 1 3 1 2 3 3 3\n",
      " 3 2 2 2 2 4 3 3 4 2 2 2 4 3 4 1 2 2 3 2 2 1 1 2 2 4 1 1 1 0 3 2 1 2 2 3 2\n",
      " 2 2 4 3 2 2 3 2 2 3 0 0 1 2 1 3 0 1 1 2 2 4 3 1 1 3 0 3 2 3 0 3 4 3 2 2 0\n",
      " 1 3 1 3 1 1 3 3 2 2 0 1 0 2 2 2 2 4 3 1 0 1 3 2 3 0 2 2 1 3 2 2 1 2 2 1 3\n",
      " 3 4 2 2 2 0 1 0 3 1 4 0 4 4 3 4 1 3 3 3 1 1 3 2 2 3 2 1 2 1 0 1 3 2 1 3 1\n",
      " 1 3 1 4 3 2 1 0 3 2 2 1 3 3 4 3 2 3 1 1 1 2 1 3 4 2 3 2 3 4 4 3 0 0 3 3 2\n",
      " 0 3 2 0 3 2 1 3 3 3 4 2 3 0 1 1 2 0 3 1 2 1 1 1 3 0 2 3 2 3 4 3 2 2 3 2 3\n",
      " 1 2 3 3 2 1 2 1 0 2 2 4 3 4 3 4 1 2 2 1 1 2 0 2 4 1 3 1 1 3 2 2 4 4 0 0 2\n",
      " 3 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "\n",
    "y_predict = knn.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "816d5573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24666666666666667\n"
     ]
    }
   ],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e135583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     actual  prediction\n",
      "0         3           0\n",
      "1         3           2\n",
      "2         4           2\n",
      "3         3           2\n",
      "4         2           0\n",
      "..      ...         ...\n",
      "295       1           2\n",
      "296       4           3\n",
      "297       4           2\n",
      "298       2           3\n",
      "299       2           3\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test \n",
    "results['prediction'] = y_predict \n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd41f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy: 0.38\n",
      "When k= 60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "highest = 0\n",
    "best_k = 0\n",
    "for i in range(1,300):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    if(highest == 0):\n",
    "        highest = accuracy\n",
    "    elif(highest < accuracy):\n",
    "        highest = accuracy\n",
    "        best_k = i\n",
    "    else:\n",
    "        pass\n",
    "print(\"The highest accuracy: \" + str(highest))\n",
    "print(\"When k= \" + str(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719dc0b",
   "metadata": {},
   "source": [
    "#### Using Cross Validation on KNN algorithm to see if the model accuary can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b5fbeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy: 0.33799999999999997\n",
      "When k= 91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "highest = 0\n",
    "best_k = 0\n",
    "for i in range(1,300):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv = 10, scoring = 'accuracy')\n",
    "    accuracy = scores.mean()\n",
    "    if(highest == 0):\n",
    "        highest = accuracy\n",
    "    elif(highest < accuracy):\n",
    "        highest = accuracy\n",
    "        best_k = i\n",
    "    else:\n",
    "        pass\n",
    "print(\"The highest accuracy: \" + str(highest))\n",
    "print(\"When k= \" + str(best_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "464f9da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=60)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 60\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2b1e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Binary Label:\n",
    "y_predict = knn.predict(X_test)\n",
    "\n",
    "# Estimating the probability (likelihood) of Each Label: \n",
    "y_predict_prob = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67117f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 3 2 2 2 4 4 2 4 2 2 3 0 1 0 1 4 2 2 0 2 3 2 1 2 2 2 4 1 1 1 3 3 3 4\n",
      " 3 1 3 2 2 1 1 2 4 4 2 3 1 4 3 4 1 3 3 2 2 2 3 4 3 2 2 4 2 1 4 3 2 1 3 4 3\n",
      " 2 3 4 2 3 3 3 2 0 1 1 3 3 2 3 0 1 1 2 1 2 4 3 4 4 2 2 1 1 2 2 3 2 3 0 2 2\n",
      " 3 1 3 1 2 2 3 1 1 2 1 2 2 3 1 2 3 3 4 1 2 0 2 1 2 1 3 0 2 1 3 0 1 3 2 2 0\n",
      " 4 3 2 2 1 2 3 3 1 3 3 2 4 1 3 4 2 2 2 3 4 1 3 4 2 3 1 4 4 3 2 1 2 3 3 1 0\n",
      " 4 2 3 2 1 4 1 4 3 1 0 2 0 1 0 3 3 3 0 0 3 3 2 2 2 2 1 2 1 2 4 2 2 2 2 4 1\n",
      " 2 3 2 3 3 2 1 1 3 4 3 1 0 3 2 3 3 2 3 0 0 2 4 0 3 2 0 1 2 3 1 1 2 4 4 4 2\n",
      " 4 2 1 1 2 4 3 1 3 2 2 2 0 3 4 2 2 1 4 2 1 2 3 2 3 2 3 1 1 4 1 1 1 2 1 3 1\n",
      " 4 4 2 2]\n",
      "[2 2 3 2 2 4 2 3 4 2 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 1 2 2 2 2 2 2 1 1 2 3 3\n",
      " 2 3 2 2 2 2 2 4 2 2 2 3 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 3 2 3 2 2 3 2 3 3\n",
      " 3 3 2 2 2 3 2 3 1 2 2 2 3 2 3 2 3 2 2 3 2 2 3 2 2 2 3 2 2 2 3 2 2 3 3 2 2\n",
      " 2 2 2 2 2 2 2 2 3 2 2 1 2 3 3 2 2 3 2 2 1 2 2 3 2 3 2 3 2 3 2 2 3 3 2 2 2\n",
      " 3 2 2 2 2 2 4 2 1 2 2 2 4 2 2 2 2 2 2 3 2 2 3 2 2 2 2 2 4 2 2 2 2 3 2 2 2\n",
      " 2 2 3 2 3 2 2 3 2 1 2 2 1 2 2 3 3 3 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2\n",
      " 2 2 3 2 2 3 2 2 3 3 4 2 3 2 2 3 2 2 2 2 3 2 2 0 2 2 3 3 2 3 3 2 3 4 3 2 2\n",
      " 3 2 2 3 2 2 2 3 2 2 3 2 3 3 3 2 2 2 2 3 1 2 2 2 4 2 2 2 2 3 2 3 2 3 2 2 2\n",
      " 1 2 2 2]\n",
      "[[0.21666667 0.26666667 0.28333333 0.18333333 0.05      ]\n",
      " [0.2        0.16666667 0.31666667 0.26666667 0.05      ]\n",
      " [0.1        0.11666667 0.3        0.36666667 0.11666667]\n",
      " ...\n",
      " [0.05       0.26666667 0.33333333 0.31666667 0.03333333]\n",
      " [0.06666667 0.15       0.38333333 0.28333333 0.11666667]\n",
      " [0.03333333 0.15       0.35       0.33333333 0.13333333]]\n",
      "[0.26666667 0.16666667 0.11666667 0.18333333 0.21666667 0.16666667\n",
      " 0.23333333 0.13333333 0.13333333 0.11666667 0.16666667 0.26666667\n",
      " 0.23333333 0.21666667 0.18333333 0.3        0.15       0.28333333\n",
      " 0.13333333 0.23333333 0.15       0.23333333 0.26666667 0.06666667\n",
      " 0.16666667 0.26666667 0.18333333 0.23333333 0.15       0.21666667\n",
      " 0.2        0.28333333 0.28333333 0.26666667 0.28333333 0.26666667\n",
      " 0.2        0.15       0.21666667 0.23333333 0.16666667 0.25\n",
      " 0.18333333 0.18333333 0.1        0.2        0.11666667 0.18333333\n",
      " 0.11666667 0.13333333 0.25       0.16666667 0.15       0.2\n",
      " 0.13333333 0.2        0.13333333 0.16666667 0.23333333 0.2\n",
      " 0.16666667 0.21666667 0.13333333 0.25       0.23333333 0.16666667\n",
      " 0.23333333 0.18333333 0.18333333 0.2        0.13333333 0.15\n",
      " 0.16666667 0.16666667 0.2        0.23333333 0.08333333 0.28333333\n",
      " 0.13333333 0.13333333 0.26666667 0.13333333 0.3        0.13333333\n",
      " 0.25       0.21666667 0.2        0.25       0.25       0.15\n",
      " 0.26666667 0.16666667 0.26666667 0.11666667 0.23333333 0.16666667\n",
      " 0.11666667 0.2        0.21666667 0.25       0.11666667 0.18333333\n",
      " 0.13333333 0.16666667 0.15       0.11666667 0.15       0.13333333\n",
      " 0.16666667 0.25       0.21666667 0.25       0.2        0.25\n",
      " 0.21666667 0.18333333 0.2        0.3        0.26666667 0.13333333\n",
      " 0.15       0.11666667 0.28333333 0.11666667 0.16666667 0.26666667\n",
      " 0.16666667 0.23333333 0.13333333 0.11666667 0.23333333 0.3\n",
      " 0.25       0.21666667 0.13333333 0.15       0.13333333 0.21666667\n",
      " 0.28333333 0.13333333 0.23333333 0.13333333 0.25       0.21666667\n",
      " 0.13333333 0.23333333 0.23333333 0.18333333 0.16666667 0.1\n",
      " 0.16666667 0.13333333 0.21666667 0.28333333 0.18333333 0.21666667\n",
      " 0.25       0.31666667 0.16666667 0.23333333 0.11666667 0.18333333\n",
      " 0.13333333 0.2        0.28333333 0.28333333 0.15       0.13333333\n",
      " 0.23333333 0.25       0.16666667 0.2        0.1        0.11666667\n",
      " 0.2        0.25       0.21666667 0.21666667 0.18333333 0.23333333\n",
      " 0.16666667 0.13333333 0.18333333 0.18333333 0.28333333 0.16666667\n",
      " 0.21666667 0.21666667 0.13333333 0.13333333 0.21666667 0.28333333\n",
      " 0.18333333 0.16666667 0.28333333 0.21666667 0.23333333 0.26666667\n",
      " 0.23333333 0.25       0.13333333 0.21666667 0.13333333 0.28333333\n",
      " 0.23333333 0.23333333 0.23333333 0.13333333 0.26666667 0.16666667\n",
      " 0.25       0.2        0.16666667 0.21666667 0.18333333 0.25\n",
      " 0.15       0.11666667 0.25       0.16666667 0.21666667 0.16666667\n",
      " 0.25       0.25       0.16666667 0.23333333 0.16666667 0.18333333\n",
      " 0.16666667 0.28333333 0.13333333 0.16666667 0.25       0.18333333\n",
      " 0.23333333 0.16666667 0.23333333 0.18333333 0.16666667 0.18333333\n",
      " 0.2        0.21666667 0.13333333 0.2        0.21666667 0.25\n",
      " 0.16666667 0.25       0.15       0.16666667 0.18333333 0.16666667\n",
      " 0.16666667 0.23333333 0.15       0.1        0.11666667 0.26666667\n",
      " 0.16666667 0.18333333 0.2        0.23333333 0.15       0.2\n",
      " 0.21666667 0.28333333 0.26666667 0.16666667 0.15       0.13333333\n",
      " 0.16666667 0.11666667 0.13333333 0.18333333 0.15       0.18333333\n",
      " 0.2        0.13333333 0.26666667 0.26666667 0.13333333 0.23333333\n",
      " 0.16666667 0.08333333 0.21666667 0.11666667 0.25       0.15\n",
      " 0.11666667 0.18333333 0.26666667 0.18333333 0.08333333 0.23333333\n",
      " 0.2        0.11666667 0.3        0.26666667 0.15       0.15      ]\n"
     ]
    }
   ],
   "source": [
    "# This line prints the \"actual label\" of the testing set:\n",
    "print(y_test)\n",
    "\n",
    "# This line prints the \"predicted label\" for the testing set:\n",
    "print(y_predict)\n",
    "\n",
    "# This line prints the \"estimated likelihood of both label\" for the testing set:\n",
    "print(y_predict_prob)\n",
    "\n",
    "# This line prints the \"estimated likelihood of label=1\" for the testing set:\n",
    "print(y_predict_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc7126",
   "metadata": {},
   "source": [
    "# True Positive Rate (TPR) and False Positive Rate (FPR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f721f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00421941 0.02109705 0.06329114 0.11392405 0.20253165\n",
      " 0.29957806 0.39240506 0.45991561 0.5443038  0.70042194 0.78059072\n",
      " 0.89873418 0.96624473 0.98312236 0.99578059 1.        ]\n",
      "[0.         0.         0.01587302 0.11111111 0.22222222 0.28571429\n",
      " 0.41269841 0.49206349 0.58730159 0.71428571 0.79365079 0.82539683\n",
      " 0.95238095 1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict_prob[:,1], pos_label=1)\n",
    "\n",
    "print(fpr)\n",
    "print(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4cca6",
   "metadata": {},
   "source": [
    "# AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d839d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5882727211841136\n"
     ]
    }
   ],
   "source": [
    "# AUC:\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3ecae",
   "metadata": {},
   "source": [
    "# ROC Curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96bd5c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the \"pyplot\" package of \"matplotlib\" library of python to generate \n",
    "# graphs and plot curves:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following line will tell Jupyter Notebook to keep the figures inside the explorer page \n",
    "# rather than openng a new figure window:\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Roc Curve:\n",
    "plt.plot(fpr, tpr, color='red', lw=2, \n",
    "         label='ROC Curve (area = %0.2f)' % AUC)\n",
    "\n",
    "# Random Guess line:\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=1, linestyle='--')\n",
    "\n",
    "# Defining The Range of X-Axis and Y-Axis:\n",
    "plt.xlim([-0.005, 1.005])\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "# Labels, Title, Legend:\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9696d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### KNN model accuracy: 0.34 when k=91 with Cross Validation\n",
    "### KNN model accuracy: 0.38 when k=60 without Cross Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
