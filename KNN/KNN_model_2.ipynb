{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac7b626",
   "metadata": {},
   "source": [
    "### Read the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed25ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Student Performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52ee65",
   "metadata": {},
   "source": [
    "### KNN Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a56ef",
   "metadata": {},
   "source": [
    "<img src=\"Model 2.jpg\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2cf11",
   "metadata": {},
   "source": [
    "### Obtain the feature matrix and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb9c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix\n",
      "[[0.72 0.72 0.74]\n",
      " [0.69 0.9  0.88]\n",
      " [0.9  0.95 0.93]\n",
      " ...\n",
      " [0.59 0.71 0.65]\n",
      " [0.68 0.78 0.77]\n",
      " [0.77 0.86 0.86]]\n",
      "size: (1000, 3)\n",
      "\n",
      "Labels\n",
      "[1 3 0 2 3 2 3 3 4 4 2 2 4 3 0 5 4 5 0 2 4 3 3 5 1 0 3 1 4 0 3 3 0 3 3 2 2\n",
      " 5 2 2 2 2 2 3 2 2 2 4 2 4 3 2 3 4 5 4 2 2 3 5 1 5 2 2 5 5 5 3 2 2 3 3 2 5\n",
      " 5 2 5 1 5 0 2 4 3 2 4 3 3 2 3 5 1 4 4 2 3 2 5 3 3 1 3 1 2 4 3 3 0 2 2 5 2\n",
      " 4 2 3 1 4 1 1 5 3 1 2 3 4 3 4 5 3 0 1 0 5 3 3 1 1 5 4 2 3 5 3 3 4 3 3 5 2\n",
      " 1 2 5 1 2 1 5 3 4 3 2 2 2 3 0 4 0 1 4 0 4 3 4 5 3 2 1 0 4 2 0 5 0 3 4 2 5\n",
      " 2 4 5 5 1 2 3 5 3 0 2 5 4 3 1 2 3 2 2 3 5 1 4 3 3 5 3 4 2 4 5 2 4 4 5 4 2\n",
      " 5 5 2 0 3 4 5 3 3 2 1 5 1 2 1 5 3 2 4 1 4 3 5 2 2 4 4 4 5 3 5 0 4 3 2 2 3\n",
      " 0 5 3 5 4 4 5 1 4 2 3 1 3 2 3 3 1 5 4 5 1 4 4 1 3 5 2 2 5 1 5 2 5 5 1 4 2\n",
      " 5 2 4 2 3 5 2 2 2 3 3 5 2 4 2 1 1 2 1 4 0 2 1 2 4 4 3 5 4 3 3 3 2 5 4 2 2\n",
      " 2 1 3 5 2 5 5 4 4 4 2 3 4 3 1 4 2 1 3 3 2 3 1 2 3 3 3 4 5 3 5 3 1 4 1 5 5\n",
      " 3 3 5 3 1 2 5 0 5 1 2 2 0 5 5 3 1 2 4 0 5 3 3 2 5 4 4 2 5 5 5 3 3 4 4 5 2\n",
      " 2 4 2 0 3 2 5 1 4 1 2 3 4 2 4 0 5 3 3 1 5 5 5 2 4 4 5 5 3 2 2 4 5 3 4 5 2\n",
      " 5 5 3 4 4 2 3 3 2 3 2 1 1 2 1 4 1 3 3 3 1 3 2 4 4 3 2 4 2 5 2 1 1 2 0 2 4\n",
      " 2 3 4 2 4 3 2 5 2 2 2 3 1 4 4 3 3 5 3 0 2 3 2 0 5 4 1 0 1 3 5 5 5 0 5 3 3\n",
      " 5 4 3 2 1 0 4 3 5 4 1 2 2 5 2 2 4 1 2 4 1 2 4 2 2 2 0 5 5 4 4 0 5 1 2 3 2\n",
      " 3 2 0 2 5 3 3 1 3 1 2 1 0 4 1 3 1 3 4 4 2 3 4 3 0 5 5 1 2 3 2 4 1 3 5 3 5\n",
      " 1 4 1 1 4 5 4 5 0 4 3 4 0 5 2 0 3 2 3 3 1 2 2 4 1 1 0 2 4 1 4 3 1 3 2 2 3\n",
      " 5 3 4 1 4 5 4 4 5 3 2 4 2 5 4 4 1 2 4 4 3 5 4 3 2 5 3 2 5 2 2 3 5 3 4 2 5\n",
      " 3 1 3 2 4 2 3 2 4 3 3 5 2 3 4 4 4 5 3 0 3 2 4 3 2 2 1 2 5 3 2 1 2 4 1 5 1\n",
      " 3 5 1 4 3 4 2 3 5 3 0 5 2 2 2 4 2 3 5 5 4 3 3 2 5 4 3 2 5 3 5 3 0 2 3 2 4\n",
      " 1 2 4 2 3 2 4 3 1 3 5 3 0 5 2 2 3 1 3 3 4 5 5 4 3 4 4 4 5 3 4 1 5 1 3 5 4\n",
      " 3 3 2 2 0 4 2 1 5 5 3 2 0 4 3 4 5 4 2 4 2 3 2 5 5 2 3 3 3 3 4 4 1 5 4 0 5\n",
      " 4 5 1 1 4 5 5 1 3 4 5 4 2 5 5 5 3 1 1 4 3 4 4 4 2 2 4 5 4 3 5 0 0 4 4 2 0\n",
      " 4 3 5 5 1 3 1 4 2 2 0 1 3 2 3 4 2 2 2 4 3 2 2 1 3 3 5 5 2 1 1 4 1 2 2 2 4\n",
      " 3 4 3 2 0 5 2 5 4 5 2 5 0 0 4 1 5 3 4 3 1 1 1 3 1 1 2 3 1 4 2 3 4 4 4 2 4\n",
      " 5 2 4 2 5 3 3 2 1 2 3 2 4 3 5 0 0 4 5 4 2 4 3 5 4 4 3 5 4 3 2 3 0 4 4 3 5\n",
      " 2 5 3 3 5 3 2 1 1 5 4 3 3 3 3 2 4 2 4 5 5 3 5 4 2 5 5 3 4 5 2 1 4 0 4 4 3\n",
      " 3]\n",
      "size: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# convert these data into 2D numpy array\n",
    "# order: math percentage, reading score percentage, writing score percentage\n",
    "X = np.array([[df['math percentage'][0], \n",
    "              df['reading score percentage'][0], \n",
    "              df['writing score percentage'][0]]], \n",
    "             dtype = 'float')\n",
    "for i in range(1,1000):\n",
    "    X = np.append(X, [[df['math percentage'][i], \n",
    "                  df['reading score percentage'][i], \n",
    "                  df['writing score percentage'][i]]],axis=0)\n",
    "print('feature matrix')\n",
    "print(X)\n",
    "print('size: ' + str(X.shape))\n",
    "print()\n",
    "\n",
    "# lavel 0: master's degree\n",
    "if(df['parental level of education'][0] == \"master's degree\"):\n",
    "    first_elem = 0\n",
    "# lavel 1: bachelor's degree\n",
    "elif(df['parental level of education'][0] == \"bachelor's degree\"):\n",
    "    first_elem = 1\n",
    "# lavel 2: associate's degree\n",
    "elif(df['parental level of education'][0] == \"associate's degree\"):\n",
    "    first_elem = 2\n",
    "# lavel 3: some college\n",
    "elif(df['parental level of education'][0] == 'some college'):\n",
    "    first_elem = 3\n",
    "# lavel 4: high school\n",
    "elif(df['parental level of education'][0] == 'high school'):\n",
    "    first_elem = 4\n",
    "# lavel 5: some high school\n",
    "else:\n",
    "    first_elem = 5\n",
    "    \n",
    "y = np.array([first_elem], dtype = 'int')\n",
    "for i in range(1,1000):\n",
    "    if(df['parental level of education'][i] == \"master's degree\"):\n",
    "        y = np.append(y, 0)\n",
    "    elif(df['parental level of education'][i] == \"bachelor's degree\"):\n",
    "        y = np.append(y, 1)\n",
    "    elif(df['parental level of education'][i] == \"associate's degree\"):\n",
    "        y = np.append(y, 2)\n",
    "    elif(df['parental level of education'][i] == 'some college'):\n",
    "        y = np.append(y, 3)\n",
    "    elif(df['parental level of education'][i] == 'high school'):\n",
    "        y = np.append(y, 4)\n",
    "    else:\n",
    "        y = np.append(y, 5)\n",
    "print('Labels')\n",
    "print(y)\n",
    "print('size: ' + str(y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f998cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# where X is all the sample data, y is all the labels\n",
    "# random_state=1 means only random once and rest stay the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6) # We can fix the random_state for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60977191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 3)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a00bf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba6c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55 0.41 0.48]\n",
      " [0.44 0.54 0.53]\n",
      " [0.7  0.64 0.7 ]\n",
      " [0.6  0.59 0.54]\n",
      " [0.7  0.56 0.51]\n",
      " [0.92 0.79 0.84]\n",
      " [0.64 0.79 0.77]\n",
      " [0.86 0.81 0.75]\n",
      " [0.99 0.93 0.9 ]\n",
      " [0.78 0.77 0.77]\n",
      " [0.73 0.76 0.78]\n",
      " [0.33 0.41 0.43]\n",
      " [0.69 0.58 0.53]\n",
      " [0.65 0.78 0.82]\n",
      " [0.45 0.59 0.64]\n",
      " [0.59 0.65 0.66]\n",
      " [0.97 0.92 0.86]\n",
      " [0.57 0.69 0.68]\n",
      " [0.81 0.8  0.76]\n",
      " [0.63 0.6  0.57]\n",
      " [0.54 0.59 0.5 ]\n",
      " [0.62 0.67 0.69]\n",
      " [0.64 0.66 0.59]\n",
      " [0.81 0.72 0.77]\n",
      " [0.73 0.76 0.78]\n",
      " [0.36 0.29 0.27]\n",
      " [0.58 0.61 0.52]\n",
      " [0.5  0.48 0.53]\n",
      " [0.81 0.88 0.9 ]\n",
      " [0.62 0.68 0.68]\n",
      " [0.68 0.54 0.53]\n",
      " [0.53 0.71 0.67]\n",
      " [0.18 0.32 0.28]\n",
      " [0.69 0.58 0.57]\n",
      " [0.4  0.52 0.43]\n",
      " [0.63 0.55 0.63]\n",
      " [0.66 0.63 0.64]\n",
      " [0.65 0.7  0.71]\n",
      " [0.66 0.65 0.6 ]\n",
      " [0.61 0.47 0.56]\n",
      " [0.43 0.62 0.61]\n",
      " [0.5  0.48 0.42]\n",
      " [0.82 0.85 0.87]\n",
      " [0.6  0.7  0.74]\n",
      " [0.87 0.73 0.72]\n",
      " [0.82 0.85 0.86]\n",
      " [0.88 0.99 0.95]\n",
      " [0.64 0.73 0.68]\n",
      " [0.69 0.65 0.74]\n",
      " [0.66 0.72 0.7 ]\n",
      " [0.37 0.45 0.38]\n",
      " [0.52 0.57 0.56]\n",
      " [0.87 0.84 0.76]\n",
      " [0.52 0.7  0.62]\n",
      " [0.79 0.73 0.67]\n",
      " [0.78 0.82 0.79]\n",
      " [0.67 0.75 0.7 ]\n",
      " [0.7  0.89 0.88]\n",
      " [0.54 0.48 0.52]\n",
      " [0.68 0.75 0.81]\n",
      " [0.67 0.76 0.75]\n",
      " [0.67 0.54 0.63]\n",
      " [0.65 0.74 0.77]\n",
      " [0.46 0.43 0.42]\n",
      " [0.5  0.5  0.47]\n",
      " [0.69 0.75 0.78]\n",
      " [0.54 0.54 0.45]\n",
      " [0.66 0.65 0.69]\n",
      " [0.85 0.86 0.98]\n",
      " [0.58 0.57 0.54]\n",
      " [0.82 0.78 0.74]\n",
      " [0.46 0.56 0.57]\n",
      " [0.73 0.67 0.59]\n",
      " [0.74 0.79 0.75]\n",
      " [0.59 0.54 0.67]\n",
      " [0.75 0.77 0.83]\n",
      " [0.85 0.75 0.68]\n",
      " [0.29 0.4  0.44]\n",
      " [0.97 1.   1.  ]\n",
      " [0.81 0.78 0.78]\n",
      " [0.4  0.42 0.38]\n",
      " [0.76 0.78 0.75]\n",
      " [0.54 0.63 0.67]\n",
      " [0.75 0.68 0.65]\n",
      " [0.3  0.24 0.15]\n",
      " [0.69 0.86 0.81]\n",
      " [0.87 0.84 0.85]\n",
      " [0.46 0.64 0.66]\n",
      " [0.62 0.66 0.68]\n",
      " [0.44 0.64 0.58]\n",
      " [0.65 0.64 0.62]\n",
      " [0.48 0.56 0.58]\n",
      " [0.58 0.67 0.72]\n",
      " [0.7  0.64 0.72]\n",
      " [0.35 0.53 0.46]\n",
      " [0.66 0.74 0.78]\n",
      " [0.81 0.75 0.78]\n",
      " [0.74 0.79 0.8 ]\n",
      " [0.74 0.64 0.6 ]\n",
      " [0.47 0.37 0.35]\n",
      " [0.81 0.77 0.79]\n",
      " [0.81 0.91 0.89]\n",
      " [0.72 0.65 0.68]\n",
      " [0.4  0.58 0.54]\n",
      " [0.71 0.66 0.65]\n",
      " [0.88 0.99 1.  ]\n",
      " [0.83 0.85 0.9 ]\n",
      " [0.74 0.71 0.78]\n",
      " [0.77 0.88 0.85]\n",
      " [0.42 0.66 0.69]\n",
      " [0.67 0.84 0.81]\n",
      " [0.69 0.77 0.78]\n",
      " [0.65 0.81 0.73]\n",
      " [0.69 0.79 0.81]\n",
      " [0.63 0.48 0.47]\n",
      " [0.55 0.61 0.54]\n",
      " [0.59 0.53 0.52]\n",
      " [0.58 0.67 0.62]\n",
      " [0.6  0.68 0.6 ]\n",
      " [0.78 0.79 0.76]\n",
      " [0.73 0.78 0.72]\n",
      " [0.9  0.95 0.93]\n",
      " [0.   0.17 0.1 ]\n",
      " [0.91 0.95 0.94]\n",
      " [0.79 0.89 0.86]\n",
      " [0.72 0.81 0.79]\n",
      " [0.63 0.69 0.74]\n",
      " [0.62 0.49 0.52]\n",
      " [0.76 0.72 0.71]\n",
      " [0.92 1.   1.  ]\n",
      " [0.64 0.53 0.57]\n",
      " [0.43 0.45 0.5 ]\n",
      " [0.5  0.67 0.73]\n",
      " [0.68 0.86 0.84]\n",
      " [0.77 0.82 0.89]\n",
      " [0.48 0.58 0.52]\n",
      " [0.72 0.72 0.74]\n",
      " [0.65 0.81 0.77]\n",
      " [0.63 0.63 0.62]\n",
      " [0.66 0.76 0.68]\n",
      " [0.75 0.84 0.8 ]\n",
      " [0.75 0.74 0.66]\n",
      " [0.68 0.8  0.76]\n",
      " [0.82 0.82 0.8 ]\n",
      " [0.73 0.68 0.66]\n",
      " [0.53 0.52 0.49]\n",
      " [0.67 0.81 0.79]\n",
      " [0.64 0.5  0.43]\n",
      " [0.77 0.79 0.8 ]\n",
      " [0.7  0.7  0.7 ]\n",
      " [0.55 0.72 0.79]\n",
      " [0.53 0.62 0.53]\n",
      " [0.49 0.53 0.52]\n",
      " [0.35 0.44 0.43]\n",
      " [0.9  0.87 0.75]\n",
      " [0.49 0.57 0.46]\n",
      " [0.51 0.54 0.41]\n",
      " [0.55 0.64 0.7 ]\n",
      " [0.52 0.59 0.56]\n",
      " [0.62 0.64 0.55]\n",
      " [1.   1.   1.  ]\n",
      " [0.85 0.84 0.78]\n",
      " [0.59 0.72 0.8 ]\n",
      " [0.93 0.9  0.83]\n",
      " [0.61 0.67 0.66]\n",
      " [0.59 0.69 0.65]\n",
      " [0.84 0.87 0.91]\n",
      " [0.77 0.82 0.91]\n",
      " [0.46 0.43 0.44]\n",
      " [0.62 0.63 0.56]\n",
      " [0.82 0.82 0.88]\n",
      " [0.59 0.51 0.43]\n",
      " [0.75 0.69 0.68]\n",
      " [0.61 0.7  0.76]\n",
      " [0.6  0.72 0.68]\n",
      " [0.46 0.43 0.41]\n",
      " [0.9  0.85 0.84]\n",
      " [0.52 0.59 0.65]\n",
      " [0.82 0.93 0.93]\n",
      " [0.73 0.83 0.76]\n",
      " [0.59 0.73 0.72]\n",
      " [0.72 0.66 0.66]\n",
      " [0.59 0.78 0.76]\n",
      " [0.67 0.86 0.83]\n",
      " [0.34 0.48 0.41]\n",
      " [0.45 0.56 0.54]\n",
      " [0.6  0.68 0.72]\n",
      " [0.8  0.9  0.82]\n",
      " [0.96 0.9  0.92]\n",
      " [0.88 0.75 0.76]\n",
      " [0.49 0.52 0.51]\n",
      " [0.52 0.67 0.72]\n",
      " [0.79 0.81 0.82]\n",
      " [0.5  0.64 0.59]\n",
      " [0.23 0.44 0.36]\n",
      " [0.61 0.51 0.52]\n",
      " [0.62 0.55 0.55]\n",
      " [0.51 0.31 0.36]\n",
      " [0.59 0.7  0.66]\n",
      " [0.64 0.6  0.58]\n",
      " [0.75 0.73 0.74]\n",
      " [0.85 0.81 0.85]\n",
      " [0.86 0.8  0.75]\n",
      " [0.71 0.83 0.77]\n",
      " [0.58 0.7  0.67]\n",
      " [0.54 0.49 0.47]\n",
      " [0.4  0.65 0.64]\n",
      " [0.58 0.75 0.77]\n",
      " [0.27 0.34 0.36]\n",
      " [0.67 0.74 0.77]\n",
      " [0.62 0.65 0.58]\n",
      " [0.42 0.52 0.51]\n",
      " [0.76 0.87 0.85]\n",
      " [0.67 0.89 0.82]\n",
      " [0.62 0.74 0.7 ]\n",
      " [0.62 0.56 0.53]\n",
      " [0.65 0.77 0.74]\n",
      " [0.49 0.63 0.56]\n",
      " [0.63 0.61 0.54]\n",
      " [0.47 0.54 0.53]\n",
      " [0.64 0.62 0.68]\n",
      " [0.46 0.61 0.55]\n",
      " [0.53 0.44 0.42]\n",
      " [0.61 0.55 0.52]\n",
      " [0.81 0.84 0.82]\n",
      " [0.55 0.47 0.44]\n",
      " [0.55 0.76 0.76]\n",
      " [0.84 0.8  0.8 ]\n",
      " [0.5  0.53 0.55]\n",
      " [0.53 0.7  0.7 ]\n",
      " [0.88 0.77 0.77]\n",
      " [0.71 0.7  0.76]\n",
      " [0.89 0.88 0.82]\n",
      " [0.61 0.86 0.87]\n",
      " [0.63 0.61 0.61]\n",
      " [0.49 0.58 0.6 ]\n",
      " [0.45 0.73 0.7 ]\n",
      " [0.73 0.75 0.8 ]\n",
      " [0.8  0.79 0.79]\n",
      " [0.35 0.61 0.54]\n",
      " [0.62 0.7  0.72]\n",
      " [0.61 0.6  0.57]\n",
      " [0.78 0.72 0.7 ]\n",
      " [0.58 0.54 0.52]\n",
      " [0.7  0.55 0.56]\n",
      " [0.48 0.45 0.41]\n",
      " [0.8  0.9  0.89]\n",
      " [0.66 0.59 0.52]\n",
      " [0.79 0.82 0.73]\n",
      " [0.74 0.9  0.88]\n",
      " [0.71 0.79 0.71]\n",
      " [0.69 0.6  0.63]\n",
      " [0.82 0.8  0.77]\n",
      " [0.61 0.42 0.41]\n",
      " [0.75 0.82 0.9 ]\n",
      " [0.87 0.74 0.7 ]\n",
      " [0.74 0.74 0.72]\n",
      " [0.56 0.72 0.65]\n",
      " [0.68 0.68 0.61]\n",
      " [0.8  0.85 0.85]\n",
      " [0.57 0.78 0.67]\n",
      " [0.58 0.62 0.59]\n",
      " [0.84 0.83 0.75]\n",
      " [0.63 0.73 0.68]\n",
      " [0.68 0.51 0.57]\n",
      " [0.27 0.34 0.32]\n",
      " [0.59 0.63 0.64]\n",
      " [0.69 0.7  0.67]\n",
      " [0.88 0.93 0.93]\n",
      " [0.84 0.77 0.74]\n",
      " [0.56 0.79 0.72]\n",
      " [0.73 0.74 0.72]\n",
      " [0.76 0.71 0.73]\n",
      " [0.76 0.78 0.8 ]\n",
      " [0.69 0.71 0.65]\n",
      " [0.57 0.61 0.54]\n",
      " [0.59 0.58 0.47]\n",
      " [0.66 0.74 0.73]\n",
      " [0.59 0.62 0.64]\n",
      " [0.48 0.52 0.45]\n",
      " [0.87 1.   0.95]\n",
      " [0.55 0.46 0.44]\n",
      " [0.63 0.75 0.81]\n",
      " [0.86 0.73 0.7 ]\n",
      " [0.61 0.56 0.55]\n",
      " [0.87 1.   1.  ]\n",
      " [0.62 0.55 0.54]\n",
      " [0.91 0.89 0.92]\n",
      " [0.77 0.69 0.68]\n",
      " [0.63 0.78 0.79]\n",
      " [0.62 0.62 0.63]\n",
      " [0.74 0.63 0.57]\n",
      " [0.82 0.75 0.77]\n",
      " [0.6  0.44 0.47]\n",
      " [0.56 0.52 0.55]\n",
      " [0.97 0.97 0.96]\n",
      " [0.61 0.58 0.62]\n",
      " [0.59 0.63 0.75]\n",
      " [0.83 0.83 0.9 ]\n",
      " [0.7  0.72 0.76]]\n",
      "\n",
      "\n",
      "[4 3 1 5 4 2 5 4 4 2 2 4 4 5 1 3 2 2 4 5 0 5 2 2 3 4 4 3 1 0 5 2 5 1 2 3 2\n",
      " 3 3 3 1 4 3 5 2 2 0 2 3 4 1 4 5 0 3 1 3 3 3 1 3 2 5 2 4 5 3 2 3 3 2 2 5 1\n",
      " 5 3 3 5 5 5 3 3 3 3 4 5 2 3 5 5 4 3 3 5 4 4 2 4 5 2 2 4 4 0 4 4 2 5 4 3 2\n",
      " 4 4 3 4 2 4 3 4 1 2 0 5 2 3 5 4 5 5 1 5 2 0 2 4 5 1 3 4 4 1 4 4 5 4 4 3 5\n",
      " 5 4 2 2 0 3 2 3 5 0 2 5 2 5 5 3 0 5 3 0 2 1 3 3 4 1 4 2 0 3 2 2 2 4 3 1 4\n",
      " 0 4 5 1 1 3 5 1 5 4 3 4 5 2 1 1 3 5 5 3 1 5 4 4 5 2 4 5 5 2 2 2 5 3 5 4 2\n",
      " 3 2 4 5 2 2 4 2 3 3 5 2 2 3 3 2 5 4 3 3 3 2 4 4 3 3 5 5 4 3 2 2 2 3 5 0 3\n",
      " 5 2 4 5 5 5 5 5 4 3 4 1 0 3 3 5 5 4 3 3 5 2 1 1 5 4 0 4 2 2 5 4 5 2 4 4 1\n",
      " 1 4 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36dfd226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy: 0.29333333333333333\n",
      "When k= 57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "highest = 0\n",
    "best_k = 0\n",
    "for i in range(1,300):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    if(highest == 0):\n",
    "        highest = accuracy\n",
    "    elif(highest < accuracy):\n",
    "        highest = accuracy\n",
    "        best_k = i\n",
    "    else:\n",
    "        pass\n",
    "print(\"The highest accuracy: \" + str(highest))\n",
    "print(\"When k= \" + str(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab5403",
   "metadata": {},
   "source": [
    "#### Using Cross Validation on KNN algorithm to see if the model accuary can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2231d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=0.20600000000000002\n",
      "k=2, accuracy=0.194\n",
      "k=3, accuracy=0.185\n",
      "k=4, accuracy=0.188\n",
      "k=5, accuracy=0.189\n",
      "k=6, accuracy=0.20400000000000001\n",
      "k=7, accuracy=0.21100000000000002\n",
      "k=8, accuracy=0.202\n",
      "k=9, accuracy=0.198\n",
      "k=10, accuracy=0.202\n",
      "k=11, accuracy=0.202\n",
      "k=12, accuracy=0.21100000000000002\n",
      "k=13, accuracy=0.199\n",
      "k=14, accuracy=0.21400000000000002\n",
      "k=15, accuracy=0.22300000000000003\n",
      "k=16, accuracy=0.22400000000000003\n",
      "k=17, accuracy=0.22999999999999998\n",
      "k=18, accuracy=0.22800000000000004\n",
      "k=19, accuracy=0.229\n",
      "k=20, accuracy=0.23899999999999996\n",
      "k=21, accuracy=0.22999999999999998\n",
      "k=22, accuracy=0.23200000000000004\n",
      "k=23, accuracy=0.23500000000000001\n",
      "k=24, accuracy=0.246\n",
      "k=25, accuracy=0.246\n",
      "k=26, accuracy=0.24299999999999997\n",
      "k=27, accuracy=0.24900000000000003\n",
      "k=28, accuracy=0.246\n",
      "k=29, accuracy=0.242\n",
      "k=30, accuracy=0.238\n",
      "k=31, accuracy=0.24\n",
      "k=32, accuracy=0.24100000000000002\n",
      "k=33, accuracy=0.24000000000000005\n",
      "k=34, accuracy=0.24099999999999996\n",
      "k=35, accuracy=0.24100000000000002\n",
      "k=36, accuracy=0.242\n",
      "k=37, accuracy=0.24499999999999997\n",
      "k=38, accuracy=0.24900000000000003\n",
      "k=39, accuracy=0.24900000000000003\n",
      "k=40, accuracy=0.24100000000000002\n",
      "k=41, accuracy=0.24300000000000002\n",
      "k=42, accuracy=0.23899999999999996\n",
      "k=43, accuracy=0.23999999999999994\n",
      "k=44, accuracy=0.233\n",
      "k=45, accuracy=0.24499999999999997\n",
      "k=46, accuracy=0.25\n",
      "k=47, accuracy=0.24699999999999997\n",
      "k=48, accuracy=0.248\n",
      "k=49, accuracy=0.24499999999999997\n",
      "k=50, accuracy=0.246\n",
      "k=51, accuracy=0.24099999999999996\n",
      "k=52, accuracy=0.24500000000000002\n",
      "k=53, accuracy=0.24299999999999997\n",
      "k=54, accuracy=0.248\n",
      "k=55, accuracy=0.24899999999999997\n",
      "k=56, accuracy=0.24499999999999997\n",
      "k=57, accuracy=0.24500000000000002\n",
      "k=58, accuracy=0.24500000000000002\n",
      "k=59, accuracy=0.246\n",
      "k=60, accuracy=0.24999999999999994\n",
      "k=61, accuracy=0.24499999999999997\n",
      "k=62, accuracy=0.246\n",
      "k=63, accuracy=0.253\n",
      "k=64, accuracy=0.24999999999999994\n",
      "k=65, accuracy=0.252\n",
      "k=66, accuracy=0.24699999999999997\n",
      "k=67, accuracy=0.24699999999999997\n",
      "k=68, accuracy=0.24500000000000002\n",
      "k=69, accuracy=0.24699999999999997\n",
      "k=70, accuracy=0.244\n",
      "k=71, accuracy=0.242\n",
      "k=72, accuracy=0.246\n",
      "k=73, accuracy=0.24400000000000005\n",
      "k=74, accuracy=0.24500000000000002\n",
      "k=75, accuracy=0.24299999999999997\n",
      "k=76, accuracy=0.244\n",
      "k=77, accuracy=0.24899999999999997\n",
      "k=78, accuracy=0.24500000000000002\n",
      "k=79, accuracy=0.24899999999999997\n",
      "k=80, accuracy=0.251\n",
      "k=81, accuracy=0.25199999999999995\n",
      "k=82, accuracy=0.253\n",
      "k=83, accuracy=0.25199999999999995\n",
      "k=84, accuracy=0.25399999999999995\n",
      "k=85, accuracy=0.24899999999999997\n",
      "k=86, accuracy=0.254\n",
      "k=87, accuracy=0.253\n",
      "k=88, accuracy=0.257\n",
      "k=89, accuracy=0.251\n",
      "k=90, accuracy=0.251\n",
      "k=91, accuracy=0.25399999999999995\n",
      "k=92, accuracy=0.257\n",
      "k=93, accuracy=0.255\n",
      "k=94, accuracy=0.251\n",
      "k=95, accuracy=0.252\n",
      "k=96, accuracy=0.253\n",
      "k=97, accuracy=0.24899999999999997\n",
      "k=98, accuracy=0.24299999999999997\n",
      "k=99, accuracy=0.244\n",
      "k=100, accuracy=0.24\n",
      "k=101, accuracy=0.24699999999999997\n",
      "k=102, accuracy=0.24499999999999997\n",
      "k=103, accuracy=0.24199999999999994\n",
      "k=104, accuracy=0.24499999999999997\n",
      "k=105, accuracy=0.242\n",
      "k=106, accuracy=0.24700000000000003\n",
      "k=107, accuracy=0.24899999999999997\n",
      "k=108, accuracy=0.24700000000000003\n",
      "k=109, accuracy=0.24499999999999997\n",
      "k=110, accuracy=0.238\n",
      "k=111, accuracy=0.24100000000000002\n",
      "k=112, accuracy=0.238\n",
      "k=113, accuracy=0.23600000000000004\n",
      "k=114, accuracy=0.23500000000000001\n",
      "k=115, accuracy=0.238\n",
      "k=116, accuracy=0.24299999999999997\n",
      "k=117, accuracy=0.24300000000000002\n",
      "k=118, accuracy=0.244\n",
      "k=119, accuracy=0.246\n",
      "k=120, accuracy=0.24699999999999997\n",
      "k=121, accuracy=0.24599999999999994\n",
      "k=122, accuracy=0.24099999999999996\n",
      "k=123, accuracy=0.246\n",
      "k=124, accuracy=0.24899999999999997\n",
      "k=125, accuracy=0.244\n",
      "k=126, accuracy=0.24999999999999994\n",
      "k=127, accuracy=0.24699999999999997\n",
      "k=128, accuracy=0.24899999999999997\n",
      "k=129, accuracy=0.24699999999999997\n",
      "k=130, accuracy=0.24299999999999997\n",
      "k=131, accuracy=0.24299999999999997\n",
      "k=132, accuracy=0.24099999999999996\n",
      "k=133, accuracy=0.24399999999999994\n",
      "k=134, accuracy=0.24299999999999997\n",
      "k=135, accuracy=0.244\n",
      "k=136, accuracy=0.242\n",
      "k=137, accuracy=0.24299999999999997\n",
      "k=138, accuracy=0.253\n",
      "k=139, accuracy=0.251\n",
      "k=140, accuracy=0.252\n",
      "k=141, accuracy=0.25\n",
      "k=142, accuracy=0.25\n",
      "k=143, accuracy=0.248\n",
      "k=144, accuracy=0.251\n",
      "k=145, accuracy=0.246\n",
      "k=146, accuracy=0.246\n",
      "k=147, accuracy=0.248\n",
      "k=148, accuracy=0.25199999999999995\n",
      "k=149, accuracy=0.253\n",
      "k=150, accuracy=0.259\n",
      "k=151, accuracy=0.253\n",
      "k=152, accuracy=0.24799999999999994\n",
      "k=153, accuracy=0.24699999999999997\n",
      "k=154, accuracy=0.251\n",
      "k=155, accuracy=0.24900000000000003\n",
      "k=156, accuracy=0.24900000000000003\n",
      "k=157, accuracy=0.255\n",
      "k=158, accuracy=0.255\n",
      "k=159, accuracy=0.259\n",
      "k=160, accuracy=0.259\n",
      "k=161, accuracy=0.261\n",
      "k=162, accuracy=0.258\n",
      "k=163, accuracy=0.259\n",
      "k=164, accuracy=0.262\n",
      "k=165, accuracy=0.258\n",
      "k=166, accuracy=0.26099999999999995\n",
      "k=167, accuracy=0.257\n",
      "k=168, accuracy=0.259\n",
      "k=169, accuracy=0.262\n",
      "k=170, accuracy=0.257\n",
      "k=171, accuracy=0.253\n",
      "k=172, accuracy=0.254\n",
      "k=173, accuracy=0.252\n",
      "k=174, accuracy=0.24900000000000003\n",
      "k=175, accuracy=0.253\n",
      "k=176, accuracy=0.24799999999999994\n",
      "k=177, accuracy=0.24300000000000002\n",
      "k=178, accuracy=0.24399999999999994\n",
      "k=179, accuracy=0.24899999999999997\n",
      "k=180, accuracy=0.24699999999999997\n",
      "k=181, accuracy=0.24800000000000005\n",
      "k=182, accuracy=0.24500000000000002\n",
      "k=183, accuracy=0.244\n",
      "k=184, accuracy=0.24899999999999997\n",
      "k=185, accuracy=0.25199999999999995\n",
      "k=186, accuracy=0.24500000000000002\n",
      "k=187, accuracy=0.24100000000000002\n",
      "k=188, accuracy=0.238\n",
      "k=189, accuracy=0.24300000000000002\n",
      "k=190, accuracy=0.24100000000000002\n",
      "k=191, accuracy=0.24\n",
      "k=192, accuracy=0.23700000000000002\n",
      "k=193, accuracy=0.23500000000000001\n",
      "k=194, accuracy=0.23399999999999999\n",
      "k=195, accuracy=0.23399999999999999\n",
      "k=196, accuracy=0.236\n",
      "k=197, accuracy=0.238\n",
      "k=198, accuracy=0.24000000000000005\n",
      "k=199, accuracy=0.238\n",
      "k=200, accuracy=0.23399999999999999\n",
      "k=201, accuracy=0.231\n",
      "k=202, accuracy=0.23400000000000004\n",
      "k=203, accuracy=0.23399999999999999\n",
      "k=204, accuracy=0.233\n",
      "k=205, accuracy=0.229\n",
      "k=206, accuracy=0.22600000000000003\n",
      "k=207, accuracy=0.22999999999999998\n",
      "k=208, accuracy=0.22799999999999998\n",
      "k=209, accuracy=0.22600000000000003\n",
      "k=210, accuracy=0.22599999999999998\n",
      "k=211, accuracy=0.225\n",
      "k=212, accuracy=0.22999999999999998\n",
      "k=213, accuracy=0.22599999999999998\n",
      "k=214, accuracy=0.22800000000000004\n",
      "k=215, accuracy=0.22700000000000004\n",
      "k=216, accuracy=0.23500000000000001\n",
      "k=217, accuracy=0.23800000000000004\n",
      "k=218, accuracy=0.23500000000000001\n",
      "k=219, accuracy=0.233\n",
      "k=220, accuracy=0.23300000000000004\n",
      "k=221, accuracy=0.231\n",
      "k=222, accuracy=0.231\n",
      "k=223, accuracy=0.236\n",
      "k=224, accuracy=0.23199999999999998\n",
      "k=225, accuracy=0.23399999999999999\n",
      "k=226, accuracy=0.233\n",
      "k=227, accuracy=0.23399999999999999\n",
      "k=228, accuracy=0.23700000000000002\n",
      "k=229, accuracy=0.23700000000000002\n",
      "k=230, accuracy=0.23199999999999998\n",
      "k=231, accuracy=0.229\n",
      "k=232, accuracy=0.22799999999999998\n",
      "k=233, accuracy=0.22699999999999995\n",
      "k=234, accuracy=0.22200000000000003\n",
      "k=235, accuracy=0.221\n",
      "k=236, accuracy=0.22799999999999998\n",
      "k=237, accuracy=0.22599999999999998\n",
      "k=238, accuracy=0.225\n",
      "k=239, accuracy=0.22599999999999998\n",
      "k=240, accuracy=0.229\n",
      "k=241, accuracy=0.22999999999999998\n",
      "k=242, accuracy=0.22999999999999998\n",
      "k=243, accuracy=0.22400000000000003\n",
      "k=244, accuracy=0.22000000000000003\n",
      "k=245, accuracy=0.21500000000000002\n",
      "k=246, accuracy=0.21600000000000003\n",
      "k=247, accuracy=0.22000000000000003\n",
      "k=248, accuracy=0.22000000000000003\n",
      "k=249, accuracy=0.22000000000000003\n",
      "k=250, accuracy=0.225\n",
      "k=251, accuracy=0.21700000000000003\n",
      "k=252, accuracy=0.219\n",
      "k=253, accuracy=0.221\n",
      "k=254, accuracy=0.22400000000000003\n",
      "k=255, accuracy=0.22299999999999995\n",
      "k=256, accuracy=0.22199999999999998\n",
      "k=257, accuracy=0.22599999999999998\n",
      "k=258, accuracy=0.219\n",
      "k=259, accuracy=0.217\n",
      "k=260, accuracy=0.219\n",
      "k=261, accuracy=0.22200000000000003\n",
      "k=262, accuracy=0.22100000000000003\n",
      "k=263, accuracy=0.22000000000000003\n",
      "k=264, accuracy=0.21800000000000003\n",
      "k=265, accuracy=0.22199999999999998\n",
      "k=266, accuracy=0.21800000000000003\n",
      "k=267, accuracy=0.221\n",
      "k=268, accuracy=0.22199999999999998\n",
      "k=269, accuracy=0.223\n",
      "k=270, accuracy=0.21600000000000003\n",
      "k=271, accuracy=0.21800000000000003\n",
      "k=272, accuracy=0.22199999999999998\n",
      "k=273, accuracy=0.22400000000000003\n",
      "k=274, accuracy=0.22300000000000003\n",
      "k=275, accuracy=0.22599999999999998\n",
      "k=276, accuracy=0.223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=277, accuracy=0.22599999999999998\n",
      "k=278, accuracy=0.233\n",
      "k=279, accuracy=0.225\n",
      "k=280, accuracy=0.23000000000000004\n",
      "k=281, accuracy=0.229\n",
      "k=282, accuracy=0.22999999999999998\n",
      "k=283, accuracy=0.23000000000000004\n",
      "k=284, accuracy=0.22800000000000004\n",
      "k=285, accuracy=0.22899999999999995\n",
      "k=286, accuracy=0.231\n",
      "k=287, accuracy=0.231\n",
      "k=288, accuracy=0.22799999999999998\n",
      "k=289, accuracy=0.22500000000000003\n",
      "k=290, accuracy=0.227\n",
      "k=291, accuracy=0.229\n",
      "k=292, accuracy=0.231\n",
      "k=293, accuracy=0.227\n",
      "k=294, accuracy=0.22799999999999998\n",
      "k=295, accuracy=0.22900000000000004\n",
      "k=296, accuracy=0.231\n",
      "k=297, accuracy=0.22999999999999998\n",
      "k=298, accuracy=0.227\n",
      "k=299, accuracy=0.22600000000000003\n",
      "The highest accuracy: 0.262\n",
      "When k= 164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "highest = 0\n",
    "best_k = 0\n",
    "for i in range(1,300):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv = 10, scoring = 'accuracy')\n",
    "    accuracy = scores.mean()\n",
    "    if(highest == 0):\n",
    "        highest = accuracy\n",
    "    elif(highest < accuracy):\n",
    "        highest = accuracy\n",
    "        best_k = i\n",
    "    else:\n",
    "        pass\n",
    "print(\"The highest accuracy: \" + str(highest))\n",
    "print(\"When k= \" + str(best_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ad01ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=57)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 57\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b046c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Binary Label:\n",
    "y_predict = knn.predict(X_test)\n",
    "\n",
    "# Estimating the probability (likelihood) of Each Label: \n",
    "y_predict_prob = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4dbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 1 5 4 2 5 4 4 2 2 4 4 5 1 3 2 2 4 5 0 5 2 2 3 4 4 3 1 0 5 2 5 1 2 3 2\n",
      " 3 3 3 1 4 3 5 2 2 0 2 3 4 1 4 5 0 3 1 3 3 3 1 3 2 5 2 4 5 3 2 3 3 2 2 5 1\n",
      " 5 3 3 5 5 5 3 3 3 3 4 5 2 3 5 5 4 3 3 5 4 4 2 4 5 2 2 4 4 0 4 4 2 5 4 3 2\n",
      " 4 4 3 4 2 4 3 4 1 2 0 5 2 3 5 4 5 5 1 5 2 0 2 4 5 1 3 4 4 1 4 4 5 4 4 3 5\n",
      " 5 4 2 2 0 3 2 3 5 0 2 5 2 5 5 3 0 5 3 0 2 1 3 3 4 1 4 2 0 3 2 2 2 4 3 1 4\n",
      " 0 4 5 1 1 3 5 1 5 4 3 4 5 2 1 1 3 5 5 3 1 5 4 4 5 2 4 5 5 2 2 2 5 3 5 4 2\n",
      " 3 2 4 5 2 2 4 2 3 3 5 2 2 3 3 2 5 4 3 3 3 2 4 4 3 3 5 5 4 3 2 2 2 3 5 0 3\n",
      " 5 2 4 5 5 5 5 5 4 3 4 1 0 3 3 5 5 4 3 3 5 2 1 1 5 4 0 4 2 2 5 4 5 2 4 4 1\n",
      " 1 4 3 3]\n",
      "[4 2 2 3 4 2 3 2 2 2 3 5 3 3 2 3 2 3 2 3 2 2 3 2 3 4 3 4 1 2 2 4 5 3 4 3 3\n",
      " 3 3 4 2 4 3 3 2 2 2 4 4 3 5 2 2 4 2 2 3 3 4 3 3 3 3 4 4 3 4 2 2 2 2 2 4 3\n",
      " 3 3 2 5 2 2 4 3 3 3 4 3 2 2 3 2 3 2 3 4 5 3 2 3 3 4 2 2 2 2 2 2 2 3 3 2 3\n",
      " 3 3 3 4 2 4 3 3 2 3 2 5 2 2 3 1 4 2 2 3 4 2 3 3 2 3 3 3 3 3 2 3 3 5 4 3 4\n",
      " 3 4 2 2 5 5 2 5 4 3 2 3 2 2 1 2 3 3 3 3 4 3 3 4 2 1 3 4 2 3 2 3 2 2 2 3 5\n",
      " 2 3 2 2 2 5 2 3 2 4 4 3 4 3 3 2 3 2 3 3 4 2 2 5 3 3 2 3 3 2 3 3 2 3 2 3 2\n",
      " 4 4 3 4 2 2 2 2 2 3 2 3 3 2 4 3 2 2 3 3 2 4 3 4 3 3 2 3 3 3 2 4 3 2 2 4 4\n",
      " 3 3 3 2 3 3 5 3 4 2 2 2 4 2 3 2 3 4 3 3 4 2 4 2 2 3 2 3 2 2 2 3 2 2 4 2 2\n",
      " 3 3 3 3]\n",
      "[[0.01754386 0.0877193  0.22807018 0.1754386  0.29824561 0.19298246]\n",
      " [0.03508772 0.10526316 0.33333333 0.0877193  0.21052632 0.22807018]\n",
      " [0.0877193  0.1754386  0.19298246 0.1754386  0.19298246 0.1754386 ]\n",
      " ...\n",
      " [0.10526316 0.1754386  0.21052632 0.26315789 0.14035088 0.10526316]\n",
      " [0.14035088 0.22807018 0.19298246 0.26315789 0.05263158 0.12280702]\n",
      " [0.05263158 0.19298246 0.1754386  0.31578947 0.1754386  0.0877193 ]]\n",
      "[0.0877193  0.10526316 0.1754386  0.0877193  0.10526316 0.14035088\n",
      " 0.22807018 0.10526316 0.19298246 0.0877193  0.0877193  0.10526316\n",
      " 0.10526316 0.1754386  0.10526316 0.07017544 0.12280702 0.12280702\n",
      " 0.10526316 0.07017544 0.07017544 0.15789474 0.14035088 0.10526316\n",
      " 0.0877193  0.07017544 0.0877193  0.07017544 0.24561404 0.15789474\n",
      " 0.10526316 0.0877193  0.0877193  0.0877193  0.07017544 0.0877193\n",
      " 0.15789474 0.24561404 0.14035088 0.05263158 0.0877193  0.05263158\n",
      " 0.19298246 0.19298246 0.10526316 0.19298246 0.26315789 0.15789474\n",
      " 0.15789474 0.22807018 0.10526316 0.07017544 0.12280702 0.12280702\n",
      " 0.0877193  0.0877193  0.1754386  0.1754386  0.0877193  0.21052632\n",
      " 0.15789474 0.12280702 0.22807018 0.07017544 0.07017544 0.21052632\n",
      " 0.0877193  0.19298246 0.22807018 0.07017544 0.07017544 0.10526316\n",
      " 0.12280702 0.01754386 0.05263158 0.10526316 0.0877193  0.10526316\n",
      " 0.21052632 0.10526316 0.10526316 0.0877193  0.05263158 0.10526316\n",
      " 0.07017544 0.10526316 0.14035088 0.10526316 0.15789474 0.10526316\n",
      " 0.1754386  0.10526316 0.14035088 0.14035088 0.0877193  0.22807018\n",
      " 0.0877193  0.07017544 0.15789474 0.07017544 0.12280702 0.1754386\n",
      " 0.14035088 0.0877193  0.1754386  0.26315789 0.22807018 0.15789474\n",
      " 0.15789474 0.12280702 0.10526316 0.15789474 0.12280702 0.14035088\n",
      " 0.05263158 0.07017544 0.0877193  0.0877193  0.10526316 0.07017544\n",
      " 0.0877193  0.19298246 0.0877193  0.21052632 0.19298246 0.07017544\n",
      " 0.22807018 0.05263158 0.12280702 0.24561404 0.05263158 0.10526316\n",
      " 0.14035088 0.14035088 0.19298246 0.0877193  0.15789474 0.1754386\n",
      " 0.12280702 0.1754386  0.0877193  0.0877193  0.10526316 0.14035088\n",
      " 0.12280702 0.10526316 0.12280702 0.03508772 0.0877193  0.15789474\n",
      " 0.21052632 0.07017544 0.0877193  0.10526316 0.14035088 0.0877193\n",
      " 0.07017544 0.14035088 0.07017544 0.0877193  0.21052632 0.14035088\n",
      " 0.24561404 0.14035088 0.15789474 0.14035088 0.21052632 0.19298246\n",
      " 0.0877193  0.10526316 0.21052632 0.07017544 0.14035088 0.22807018\n",
      " 0.15789474 0.07017544 0.15789474 0.10526316 0.19298246 0.01754386\n",
      " 0.1754386  0.15789474 0.21052632 0.12280702 0.10526316 0.10526316\n",
      " 0.15789474 0.15789474 0.19298246 0.14035088 0.07017544 0.14035088\n",
      " 0.12280702 0.12280702 0.0877193  0.07017544 0.0877193  0.07017544\n",
      " 0.15789474 0.0877193  0.10526316 0.15789474 0.12280702 0.05263158\n",
      " 0.12280702 0.0877193  0.10526316 0.22807018 0.0877193  0.21052632\n",
      " 0.10526316 0.07017544 0.12280702 0.12280702 0.19298246 0.0877193\n",
      " 0.15789474 0.0877193  0.0877193  0.0877193  0.12280702 0.10526316\n",
      " 0.07017544 0.0877193  0.15789474 0.0877193  0.1754386  0.14035088\n",
      " 0.10526316 0.12280702 0.14035088 0.19298246 0.15789474 0.1754386\n",
      " 0.10526316 0.12280702 0.14035088 0.14035088 0.07017544 0.10526316\n",
      " 0.1754386  0.07017544 0.0877193  0.0877193  0.10526316 0.07017544\n",
      " 0.21052632 0.0877193  0.07017544 0.14035088 0.07017544 0.1754386\n",
      " 0.0877193  0.0877193  0.1754386  0.10526316 0.12280702 0.12280702\n",
      " 0.12280702 0.19298246 0.14035088 0.05263158 0.0877193  0.1754386\n",
      " 0.0877193  0.0877193  0.05263158 0.12280702 0.22807018 0.0877193\n",
      " 0.1754386  0.12280702 0.14035088 0.10526316 0.14035088 0.0877193\n",
      " 0.07017544 0.19298246 0.05263158 0.05263158 0.28070175 0.0877193\n",
      " 0.21052632 0.0877193  0.0877193  0.26315789 0.0877193  0.12280702\n",
      " 0.12280702 0.19298246 0.10526316 0.15789474 0.0877193  0.0877193\n",
      " 0.0877193  0.21052632 0.07017544 0.1754386  0.22807018 0.19298246]\n"
     ]
    }
   ],
   "source": [
    "# This line prints the \"actual label\" of the testing set:\n",
    "print(y_test)\n",
    "\n",
    "# This line prints the \"predicted label\" for the testing set:\n",
    "print(y_predict)\n",
    "\n",
    "# This line prints the \"estimated likelihood of both label\" for the testing set:\n",
    "print(y_predict_prob)\n",
    "\n",
    "# This line prints the \"estimated likelihood of label=1\" for the testing set:\n",
    "print(y_predict_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f82aef",
   "metadata": {},
   "source": [
    "# True Positive Rate (TPR) and False Positive Rate (FPR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8b81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.003663   0.01465201 0.02197802 0.05860806 0.0952381\n",
      " 0.15384615 0.21245421 0.3003663  0.3956044  0.4981685  0.63736264\n",
      " 0.83150183 0.94871795 0.99267399 0.996337   1.        ]\n",
      "[0.         0.         0.         0.07407407 0.11111111 0.22222222\n",
      " 0.25925926 0.33333333 0.37037037 0.40740741 0.48148148 0.62962963\n",
      " 0.88888889 0.96296296 0.96296296 0.96296296 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict_prob[:,1], pos_label=1)\n",
    "\n",
    "print(fpr)\n",
    "print(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e6d7f",
   "metadata": {},
   "source": [
    "# AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40975099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5375118708452042\n"
     ]
    }
   ],
   "source": [
    "# AUC:\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820735f5",
   "metadata": {},
   "source": [
    "# ROC Curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84eef975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the \"pyplot\" package of \"matplotlib\" library of python to generate \n",
    "# graphs and plot curves:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following line will tell Jupyter Notebook to keep the figures inside the explorer page \n",
    "# rather than openng a new figure window:\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Roc Curve:\n",
    "plt.plot(fpr, tpr, color='red', lw=2, \n",
    "         label='ROC Curve (area = %0.2f)' % AUC)\n",
    "\n",
    "# Random Guess line:\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=1, linestyle='--')\n",
    "\n",
    "# Defining The Range of X-Axis and Y-Axis:\n",
    "plt.xlim([-0.005, 1.005])\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "# Labels, Title, Legend:\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2e579",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### KNN model accuracy: 0.26 when k=164 with Cross Validation\n",
    "### KNN model accuracy: 0.29 when k=57 without Cross Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
