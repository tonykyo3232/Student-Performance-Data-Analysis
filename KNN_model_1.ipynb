{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7127cb0",
   "metadata": {},
   "source": [
    "### Read the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5286f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Student Performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e8973",
   "metadata": {},
   "source": [
    "### KNN Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a393d",
   "metadata": {},
   "source": [
    "<img src=\"Model 1.jpg\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4444b3",
   "metadata": {},
   "source": [
    "### Obtain the feature matrix and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe636c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix\n",
      "[[0.72 0.72 0.74]\n",
      " [0.69 0.9  0.88]\n",
      " [0.9  0.95 0.93]\n",
      " ...\n",
      " [0.59 0.71 0.65]\n",
      " [0.68 0.78 0.77]\n",
      " [0.77 0.86 0.86]]\n",
      "size: (1000, 3)\n",
      "\n",
      "Labels\n",
      "[1 2 1 0 2 1 1 1 3 1 2 3 1 0 0 2 2 1 2 2 3 1 3 2 3 0 1 2 2 3 3 1 4 3 4 4 3\n",
      " 3 3 1 2 2 1 1 4 1 0 2 3 2 4 4 2 3 2 2 4 3 3 2 4 0 0 2 3 1 3 2 1 2 3 3 0 2\n",
      " 2 1 4 0 3 4 1 1 0 4 3 2 2 3 0 3 2 2 2 2 1 2 1 4 3 3 1 3 3 1 2 2 3 4 1 1 3\n",
      " 2 0 3 4 2 1 3 3 2 2 1 2 3 4 1 1 3 3 0 3 2 4 2 3 2 1 4 2 3 3 2 4 0 3 2 1 2\n",
      " 3 4 0 0 1 3 3 2 4 1 1 3 1 4 1 2 4 2 2 1 1 2 0 4 3 2 2 2 1 2 1 3 2 2 4 3 2\n",
      " 2 4 3 1 2 4 3 1 3 2 3 2 4 1 1 2 3 2 1 2 3 4 4 1 1 3 2 2 2 4 1 4 2 1 1 3 1\n",
      " 2 3 1 4 2 3 0 2 3 2 1 4 2 3 3 3 1 2 3 4 3 4 3 2 4 1 1 2 0 3 1 3 3 4 2 2 1\n",
      " 2 2 2 2 4 3 3 2 3 3 4 2 2 3 3 1 2 2 4 2 1 3 3 3 3 1 1 4 1 1 4 2 3 2 4 3 1\n",
      " 0 4 2 3 0 3 2 1 2 0 4 2 1 3 1 1 3 2 2 2 3 2 1 3 2 4 2 2 2 2 2 0 2 1 2 2 4\n",
      " 1 2 1 3 2 1 3 2 2 1 3 3 2 1 2 3 4 1 4 2 2 2 1 0 2 3 3 1 1 2 3 2 0 2 2 0 3\n",
      " 4 2 3 3 3 4 3 3 0 0 1 2 2 4 0 4 4 2 3 3 4 3 4 2 2 0 1 2 1 3 2 0 0 3 2 2 1\n",
      " 1 3 3 3 4 3 1 2 4 2 2 3 4 2 3 3 0 1 2 2 2 0 2 2 2 2 0 2 2 3 3 2 3 2 3 0 1\n",
      " 0 2 3 2 1 1 2 4 2 2 2 2 3 3 4 1 2 1 4 2 0 2 3 0 0 2 2 2 2 3 1 3 4 3 3 4 1\n",
      " 3 2 0 1 2 3 2 1 0 0 2 2 2 1 3 2 3 1 4 3 1 2 4 3 1 0 1 2 2 3 0 3 1 1 2 3 4\n",
      " 3 1 3 2 3 2 2 4 2 2 3 2 2 2 4 4 1 2 2 3 4 0 2 3 2 3 3 4 0 2 2 2 2 1 1 3 4\n",
      " 2 2 2 1 3 3 2 2 3 1 1 4 3 1 3 1 0 2 2 4 0 0 1 1 3 3 4 3 3 3 2 0 2 2 0 2 0\n",
      " 4 4 2 2 1 0 3 3 3 2 4 3 3 2 2 2 4 1 3 2 2 2 0 2 4 3 3 2 2 1 2 0 4 3 1 3 3\n",
      " 2 3 1 1 2 3 0 1 3 4 3 3 3 1 4 1 1 3 4 1 3 2 0 3 0 1 1 2 3 3 3 2 2 3 2 3 2\n",
      " 2 1 2 3 2 3 2 2 3 1 4 2 3 3 3 1 1 2 1 4 4 3 0 4 2 4 2 3 2 3 2 0 3 2 4 1 0\n",
      " 3 1 0 3 2 3 3 2 4 3 3 1 1 2 2 2 4 2 3 1 2 1 4 4 4 3 2 1 0 2 3 4 2 2 1 3 2\n",
      " 3 0 2 2 1 3 3 2 2 1 3 4 2 2 2 4 3 4 3 1 2 3 3 1 3 1 2 1 3 0 1 3 1 2 1 1 1\n",
      " 2 0 4 3 1 1 2 2 1 4 1 2 2 1 3 3 4 1 4 3 4 4 2 2 2 4 1 2 0 3 4 2 1 0 0 2 4\n",
      " 2 1 0 3 1 2 0 3 4 1 2 2 2 2 3 1 0 2 0 1 1 2 4 0 1 2 3 2 1 1 3 4 2 3 2 3 2\n",
      " 0 4 4 2 1 1 2 1 2 2 4 3 2 2 3 2 1 4 2 1 2 1 4 2 2 3 2 3 3 2 4 1 3 4 2 4 2\n",
      " 3 3 4 4 0 3 4 4 1 1 3 3 3 2 0 3 3 3 1 3 2 4 3 0 2 2 1 4 4 2 2 1 3 2 3 1 3\n",
      " 4 4 3 4 2 2 3 3 2 2 3 0 4 3 3 2 3 2 0 1 2 1 3 1 4 4 3 4 2 2 4 2 3 3 2 0 3\n",
      " 4 2 3 3 0 2 4 1 3 2 0 3 0 2 1 2 3 2 1 3 1 0 2 0 2 4 0 3 4 1 3 3 0 4 2 2 3\n",
      " 3]\n",
      "size: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# convert these data into 2D numpy array\n",
    "# order: math percentage, reading score percentage, writing score percentage\n",
    "X = np.array([[df['math percentage'][0], \n",
    "              df['reading score percentage'][0], \n",
    "              df['writing score percentage'][0]]], \n",
    "             dtype = 'float')\n",
    "for i in range(1,1000):\n",
    "    X = np.append(X, [[df['math percentage'][i], \n",
    "                  df['reading score percentage'][i], \n",
    "                  df['writing score percentage'][i]]],axis=0)\n",
    "print('feature matrix')\n",
    "print(X)\n",
    "print('size: ' + str(X.shape))\n",
    "print()\n",
    "\n",
    "# Group A to Group E labeled as 0,1,2,3,4\n",
    "if(df['race/ethnicity'][0] == 'group A'):\n",
    "    first_elem = 0\n",
    "elif(df['race/ethnicity'][0] == 'group B'):\n",
    "    first_elem = 1\n",
    "elif(df['race/ethnicity'][0] == 'group C'):\n",
    "    first_elem = 2\n",
    "elif(df['race/ethnicity'][0] == 'group D'):\n",
    "    first_elem = 3\n",
    "else:\n",
    "    first_elem = 4\n",
    "    \n",
    "y = np.array([first_elem], dtype = 'int')\n",
    "for i in range(1,1000):\n",
    "    if(df['race/ethnicity'][i] == 'group A'):\n",
    "        y = np.append(y, 0)\n",
    "    elif(df['race/ethnicity'][i] == 'group B'):\n",
    "        y = np.append(y, 1)\n",
    "    elif(df['race/ethnicity'][i] == 'group C'):\n",
    "        y = np.append(y, 2)\n",
    "    elif(df['race/ethnicity'][i] == 'group D'):\n",
    "        y = np.append(y, 3)\n",
    "    else:\n",
    "        y = np.append(y, 4)\n",
    "print('Labels')\n",
    "print(y)\n",
    "print('size: ' + str(y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3500e6",
   "metadata": {},
   "source": [
    "Using KNN to do the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64dfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following line, \"knn\" is instantiated as an \"object\" of 'KNeighborsClassifier' \"class\". \n",
    "# most of the time we use default k value\n",
    "k = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580642ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the method \"fit\" of the \"object knn\" along with training dataset and labels to train the model.\n",
    "# where:\n",
    "# X = iris.data  # X will be 'feature matrix'\n",
    "# y = iris.target  # y will be 'label vector'\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6536918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "# X: feature, Y: label\n",
    "X_Testing = [[0.72,0.72,0.74]]\n",
    "y_predict = knn.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6ca238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "# Two new data samples:\n",
    "# if there are 2 new flowers and want to detect both of them\n",
    "# [0, 1, 2] => ['setosa' 'versicolor' 'virginica']\n",
    "X_Testing = [[0.72,0.72,0.74],[0.69,0.9,0.88]]\n",
    "y_predict = knn.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfb0ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# where X is all the sample data, y is all the labels\n",
    "# random_state=1 means only random once and rest stay the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6) # We can fix the random_state for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "913bcbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 3)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "573a908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7282a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55 0.41 0.48]\n",
      " [0.44 0.54 0.53]\n",
      " [0.7  0.64 0.7 ]\n",
      " [0.6  0.59 0.54]\n",
      " [0.7  0.56 0.51]\n",
      " [0.92 0.79 0.84]\n",
      " [0.64 0.79 0.77]\n",
      " [0.86 0.81 0.75]\n",
      " [0.99 0.93 0.9 ]\n",
      " [0.78 0.77 0.77]\n",
      " [0.73 0.76 0.78]\n",
      " [0.33 0.41 0.43]\n",
      " [0.69 0.58 0.53]\n",
      " [0.65 0.78 0.82]\n",
      " [0.45 0.59 0.64]\n",
      " [0.59 0.65 0.66]\n",
      " [0.97 0.92 0.86]\n",
      " [0.57 0.69 0.68]\n",
      " [0.81 0.8  0.76]\n",
      " [0.63 0.6  0.57]\n",
      " [0.54 0.59 0.5 ]\n",
      " [0.62 0.67 0.69]\n",
      " [0.64 0.66 0.59]\n",
      " [0.81 0.72 0.77]\n",
      " [0.73 0.76 0.78]\n",
      " [0.36 0.29 0.27]\n",
      " [0.58 0.61 0.52]\n",
      " [0.5  0.48 0.53]\n",
      " [0.81 0.88 0.9 ]\n",
      " [0.62 0.68 0.68]\n",
      " [0.68 0.54 0.53]\n",
      " [0.53 0.71 0.67]\n",
      " [0.18 0.32 0.28]\n",
      " [0.69 0.58 0.57]\n",
      " [0.4  0.52 0.43]\n",
      " [0.63 0.55 0.63]\n",
      " [0.66 0.63 0.64]\n",
      " [0.65 0.7  0.71]\n",
      " [0.66 0.65 0.6 ]\n",
      " [0.61 0.47 0.56]\n",
      " [0.43 0.62 0.61]\n",
      " [0.5  0.48 0.42]\n",
      " [0.82 0.85 0.87]\n",
      " [0.6  0.7  0.74]\n",
      " [0.87 0.73 0.72]\n",
      " [0.82 0.85 0.86]\n",
      " [0.88 0.99 0.95]\n",
      " [0.64 0.73 0.68]\n",
      " [0.69 0.65 0.74]\n",
      " [0.66 0.72 0.7 ]\n",
      " [0.37 0.45 0.38]\n",
      " [0.52 0.57 0.56]\n",
      " [0.87 0.84 0.76]\n",
      " [0.52 0.7  0.62]\n",
      " [0.79 0.73 0.67]\n",
      " [0.78 0.82 0.79]\n",
      " [0.67 0.75 0.7 ]\n",
      " [0.7  0.89 0.88]\n",
      " [0.54 0.48 0.52]\n",
      " [0.68 0.75 0.81]\n",
      " [0.67 0.76 0.75]\n",
      " [0.67 0.54 0.63]\n",
      " [0.65 0.74 0.77]\n",
      " [0.46 0.43 0.42]\n",
      " [0.5  0.5  0.47]\n",
      " [0.69 0.75 0.78]\n",
      " [0.54 0.54 0.45]\n",
      " [0.66 0.65 0.69]\n",
      " [0.85 0.86 0.98]\n",
      " [0.58 0.57 0.54]\n",
      " [0.82 0.78 0.74]\n",
      " [0.46 0.56 0.57]\n",
      " [0.73 0.67 0.59]\n",
      " [0.74 0.79 0.75]\n",
      " [0.59 0.54 0.67]\n",
      " [0.75 0.77 0.83]\n",
      " [0.85 0.75 0.68]\n",
      " [0.29 0.4  0.44]\n",
      " [0.97 1.   1.  ]\n",
      " [0.81 0.78 0.78]\n",
      " [0.4  0.42 0.38]\n",
      " [0.76 0.78 0.75]\n",
      " [0.54 0.63 0.67]\n",
      " [0.75 0.68 0.65]\n",
      " [0.3  0.24 0.15]\n",
      " [0.69 0.86 0.81]\n",
      " [0.87 0.84 0.85]\n",
      " [0.46 0.64 0.66]\n",
      " [0.62 0.66 0.68]\n",
      " [0.44 0.64 0.58]\n",
      " [0.65 0.64 0.62]\n",
      " [0.48 0.56 0.58]\n",
      " [0.58 0.67 0.72]\n",
      " [0.7  0.64 0.72]\n",
      " [0.35 0.53 0.46]\n",
      " [0.66 0.74 0.78]\n",
      " [0.81 0.75 0.78]\n",
      " [0.74 0.79 0.8 ]\n",
      " [0.74 0.64 0.6 ]\n",
      " [0.47 0.37 0.35]\n",
      " [0.81 0.77 0.79]\n",
      " [0.81 0.91 0.89]\n",
      " [0.72 0.65 0.68]\n",
      " [0.4  0.58 0.54]\n",
      " [0.71 0.66 0.65]\n",
      " [0.88 0.99 1.  ]\n",
      " [0.83 0.85 0.9 ]\n",
      " [0.74 0.71 0.78]\n",
      " [0.77 0.88 0.85]\n",
      " [0.42 0.66 0.69]\n",
      " [0.67 0.84 0.81]\n",
      " [0.69 0.77 0.78]\n",
      " [0.65 0.81 0.73]\n",
      " [0.69 0.79 0.81]\n",
      " [0.63 0.48 0.47]\n",
      " [0.55 0.61 0.54]\n",
      " [0.59 0.53 0.52]\n",
      " [0.58 0.67 0.62]\n",
      " [0.6  0.68 0.6 ]\n",
      " [0.78 0.79 0.76]\n",
      " [0.73 0.78 0.72]\n",
      " [0.9  0.95 0.93]\n",
      " [0.   0.17 0.1 ]\n",
      " [0.91 0.95 0.94]\n",
      " [0.79 0.89 0.86]\n",
      " [0.72 0.81 0.79]\n",
      " [0.63 0.69 0.74]\n",
      " [0.62 0.49 0.52]\n",
      " [0.76 0.72 0.71]\n",
      " [0.92 1.   1.  ]\n",
      " [0.64 0.53 0.57]\n",
      " [0.43 0.45 0.5 ]\n",
      " [0.5  0.67 0.73]\n",
      " [0.68 0.86 0.84]\n",
      " [0.77 0.82 0.89]\n",
      " [0.48 0.58 0.52]\n",
      " [0.72 0.72 0.74]\n",
      " [0.65 0.81 0.77]\n",
      " [0.63 0.63 0.62]\n",
      " [0.66 0.76 0.68]\n",
      " [0.75 0.84 0.8 ]\n",
      " [0.75 0.74 0.66]\n",
      " [0.68 0.8  0.76]\n",
      " [0.82 0.82 0.8 ]\n",
      " [0.73 0.68 0.66]\n",
      " [0.53 0.52 0.49]\n",
      " [0.67 0.81 0.79]\n",
      " [0.64 0.5  0.43]\n",
      " [0.77 0.79 0.8 ]\n",
      " [0.7  0.7  0.7 ]\n",
      " [0.55 0.72 0.79]\n",
      " [0.53 0.62 0.53]\n",
      " [0.49 0.53 0.52]\n",
      " [0.35 0.44 0.43]\n",
      " [0.9  0.87 0.75]\n",
      " [0.49 0.57 0.46]\n",
      " [0.51 0.54 0.41]\n",
      " [0.55 0.64 0.7 ]\n",
      " [0.52 0.59 0.56]\n",
      " [0.62 0.64 0.55]\n",
      " [1.   1.   1.  ]\n",
      " [0.85 0.84 0.78]\n",
      " [0.59 0.72 0.8 ]\n",
      " [0.93 0.9  0.83]\n",
      " [0.61 0.67 0.66]\n",
      " [0.59 0.69 0.65]\n",
      " [0.84 0.87 0.91]\n",
      " [0.77 0.82 0.91]\n",
      " [0.46 0.43 0.44]\n",
      " [0.62 0.63 0.56]\n",
      " [0.82 0.82 0.88]\n",
      " [0.59 0.51 0.43]\n",
      " [0.75 0.69 0.68]\n",
      " [0.61 0.7  0.76]\n",
      " [0.6  0.72 0.68]\n",
      " [0.46 0.43 0.41]\n",
      " [0.9  0.85 0.84]\n",
      " [0.52 0.59 0.65]\n",
      " [0.82 0.93 0.93]\n",
      " [0.73 0.83 0.76]\n",
      " [0.59 0.73 0.72]\n",
      " [0.72 0.66 0.66]\n",
      " [0.59 0.78 0.76]\n",
      " [0.67 0.86 0.83]\n",
      " [0.34 0.48 0.41]\n",
      " [0.45 0.56 0.54]\n",
      " [0.6  0.68 0.72]\n",
      " [0.8  0.9  0.82]\n",
      " [0.96 0.9  0.92]\n",
      " [0.88 0.75 0.76]\n",
      " [0.49 0.52 0.51]\n",
      " [0.52 0.67 0.72]\n",
      " [0.79 0.81 0.82]\n",
      " [0.5  0.64 0.59]\n",
      " [0.23 0.44 0.36]\n",
      " [0.61 0.51 0.52]\n",
      " [0.62 0.55 0.55]\n",
      " [0.51 0.31 0.36]\n",
      " [0.59 0.7  0.66]\n",
      " [0.64 0.6  0.58]\n",
      " [0.75 0.73 0.74]\n",
      " [0.85 0.81 0.85]\n",
      " [0.86 0.8  0.75]\n",
      " [0.71 0.83 0.77]\n",
      " [0.58 0.7  0.67]\n",
      " [0.54 0.49 0.47]\n",
      " [0.4  0.65 0.64]\n",
      " [0.58 0.75 0.77]\n",
      " [0.27 0.34 0.36]\n",
      " [0.67 0.74 0.77]\n",
      " [0.62 0.65 0.58]\n",
      " [0.42 0.52 0.51]\n",
      " [0.76 0.87 0.85]\n",
      " [0.67 0.89 0.82]\n",
      " [0.62 0.74 0.7 ]\n",
      " [0.62 0.56 0.53]\n",
      " [0.65 0.77 0.74]\n",
      " [0.49 0.63 0.56]\n",
      " [0.63 0.61 0.54]\n",
      " [0.47 0.54 0.53]\n",
      " [0.64 0.62 0.68]\n",
      " [0.46 0.61 0.55]\n",
      " [0.53 0.44 0.42]\n",
      " [0.61 0.55 0.52]\n",
      " [0.81 0.84 0.82]\n",
      " [0.55 0.47 0.44]\n",
      " [0.55 0.76 0.76]\n",
      " [0.84 0.8  0.8 ]\n",
      " [0.5  0.53 0.55]\n",
      " [0.53 0.7  0.7 ]\n",
      " [0.88 0.77 0.77]\n",
      " [0.71 0.7  0.76]\n",
      " [0.89 0.88 0.82]\n",
      " [0.61 0.86 0.87]\n",
      " [0.63 0.61 0.61]\n",
      " [0.49 0.58 0.6 ]\n",
      " [0.45 0.73 0.7 ]\n",
      " [0.73 0.75 0.8 ]\n",
      " [0.8  0.79 0.79]\n",
      " [0.35 0.61 0.54]\n",
      " [0.62 0.7  0.72]\n",
      " [0.61 0.6  0.57]\n",
      " [0.78 0.72 0.7 ]\n",
      " [0.58 0.54 0.52]\n",
      " [0.7  0.55 0.56]\n",
      " [0.48 0.45 0.41]\n",
      " [0.8  0.9  0.89]\n",
      " [0.66 0.59 0.52]\n",
      " [0.79 0.82 0.73]\n",
      " [0.74 0.9  0.88]\n",
      " [0.71 0.79 0.71]\n",
      " [0.69 0.6  0.63]\n",
      " [0.82 0.8  0.77]\n",
      " [0.61 0.42 0.41]\n",
      " [0.75 0.82 0.9 ]\n",
      " [0.87 0.74 0.7 ]\n",
      " [0.74 0.74 0.72]\n",
      " [0.56 0.72 0.65]\n",
      " [0.68 0.68 0.61]\n",
      " [0.8  0.85 0.85]\n",
      " [0.57 0.78 0.67]\n",
      " [0.58 0.62 0.59]\n",
      " [0.84 0.83 0.75]\n",
      " [0.63 0.73 0.68]\n",
      " [0.68 0.51 0.57]\n",
      " [0.27 0.34 0.32]\n",
      " [0.59 0.63 0.64]\n",
      " [0.69 0.7  0.67]\n",
      " [0.88 0.93 0.93]\n",
      " [0.84 0.77 0.74]\n",
      " [0.56 0.79 0.72]\n",
      " [0.73 0.74 0.72]\n",
      " [0.76 0.71 0.73]\n",
      " [0.76 0.78 0.8 ]\n",
      " [0.69 0.71 0.65]\n",
      " [0.57 0.61 0.54]\n",
      " [0.59 0.58 0.47]\n",
      " [0.66 0.74 0.73]\n",
      " [0.59 0.62 0.64]\n",
      " [0.48 0.52 0.45]\n",
      " [0.87 1.   0.95]\n",
      " [0.55 0.46 0.44]\n",
      " [0.63 0.75 0.81]\n",
      " [0.86 0.73 0.7 ]\n",
      " [0.61 0.56 0.55]\n",
      " [0.87 1.   1.  ]\n",
      " [0.62 0.55 0.54]\n",
      " [0.91 0.89 0.92]\n",
      " [0.77 0.69 0.68]\n",
      " [0.63 0.78 0.79]\n",
      " [0.62 0.62 0.63]\n",
      " [0.74 0.63 0.57]\n",
      " [0.82 0.75 0.77]\n",
      " [0.6  0.44 0.47]\n",
      " [0.56 0.52 0.55]\n",
      " [0.97 0.97 0.96]\n",
      " [0.61 0.58 0.62]\n",
      " [0.59 0.63 0.75]\n",
      " [0.83 0.83 0.9 ]\n",
      " [0.7  0.72 0.76]]\n",
      "\n",
      "\n",
      "[3 3 4 3 2 2 2 4 4 2 4 2 2 3 0 1 0 1 4 2 2 0 2 3 2 1 2 2 2 4 1 1 1 3 3 3 4\n",
      " 3 1 3 2 2 1 1 2 4 4 2 3 1 4 3 4 1 3 3 2 2 2 3 4 3 2 2 4 2 1 4 3 2 1 3 4 3\n",
      " 2 3 4 2 3 3 3 2 0 1 1 3 3 2 3 0 1 1 2 1 2 4 3 4 4 2 2 1 1 2 2 3 2 3 0 2 2\n",
      " 3 1 3 1 2 2 3 1 1 2 1 2 2 3 1 2 3 3 4 1 2 0 2 1 2 1 3 0 2 1 3 0 1 3 2 2 0\n",
      " 4 3 2 2 1 2 3 3 1 3 3 2 4 1 3 4 2 2 2 3 4 1 3 4 2 3 1 4 4 3 2 1 2 3 3 1 0\n",
      " 4 2 3 2 1 4 1 4 3 1 0 2 0 1 0 3 3 3 0 0 3 3 2 2 2 2 1 2 1 2 4 2 2 2 2 4 1\n",
      " 2 3 2 3 3 2 1 1 3 4 3 1 0 3 2 3 3 2 3 0 0 2 4 0 3 2 0 1 2 3 1 1 2 4 4 4 2\n",
      " 4 2 1 1 2 4 3 1 3 2 2 2 0 3 4 2 2 1 4 2 1 2 3 2 3 2 3 1 1 4 1 1 1 2 1 3 1\n",
      " 4 4 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15df71fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8a0c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 2 0 3 3 1 2 4 3 2 0 2 3 2 0 1 3 1 3 1 2 2 3 2 1 0 3 2 1 3 1 2 3 3 3\n",
      " 3 2 2 2 2 4 3 3 4 2 2 2 4 3 4 1 2 2 3 2 2 1 1 2 2 4 1 1 1 0 3 2 1 2 2 3 2\n",
      " 2 2 4 3 2 2 3 2 2 3 0 0 1 2 1 3 0 1 1 2 2 4 3 1 1 3 0 3 2 3 0 3 4 3 2 2 0\n",
      " 1 3 1 3 1 1 3 3 2 2 0 1 0 2 2 2 2 4 3 1 0 1 3 2 3 0 2 2 1 3 2 2 1 2 2 1 3\n",
      " 3 4 2 2 2 0 1 0 3 1 4 0 4 4 3 4 1 3 3 3 1 1 3 2 2 3 2 1 2 1 0 1 3 2 1 3 1\n",
      " 1 3 1 4 3 2 1 0 3 2 2 1 3 3 4 3 2 3 1 1 1 2 1 3 4 2 3 2 3 4 4 3 0 0 3 3 2\n",
      " 0 3 2 0 3 2 1 3 3 3 4 2 3 0 1 1 2 0 3 1 2 1 1 1 3 0 2 3 2 3 4 3 2 2 3 2 3\n",
      " 1 2 3 3 2 1 2 1 0 2 2 4 3 4 3 4 1 2 2 1 1 2 0 2 4 1 3 1 1 3 2 2 4 4 0 0 2\n",
      " 3 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "\n",
    "y_predict = knn.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "816d5573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24666666666666667\n"
     ]
    }
   ],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e135583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     actual  prediction\n",
      "0         3           0\n",
      "1         3           2\n",
      "2         4           2\n",
      "3         3           2\n",
      "4         2           0\n",
      "..      ...         ...\n",
      "295       1           2\n",
      "296       4           3\n",
      "297       4           2\n",
      "298       2           3\n",
      "299       2           3\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test \n",
    "results['prediction'] = y_predict \n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd41f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "highest = 0\n",
    "for i in range(1,300):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "#     print('k=' + str(i) + ', accuracy=' + str(accuracy))\n",
    "    if(highest == 0):\n",
    "        highest = accuracy\n",
    "    elif(highest < accuracy):\n",
    "        highest = accuracy\n",
    "    else:\n",
    "        pass\n",
    "print(\"The highest accuracy: \" + str(highest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
