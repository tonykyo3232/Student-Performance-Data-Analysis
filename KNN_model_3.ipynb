{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9202297f",
   "metadata": {},
   "source": [
    "### Read the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1401cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Student Performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cdd460",
   "metadata": {},
   "source": [
    "### KNN Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc2dde",
   "metadata": {},
   "source": [
    "<img src=\"Model 3.jpg\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541041e8",
   "metadata": {},
   "source": [
    "### Obtain the feature matrix and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c4c4209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix\n",
      "[[0.72 0.72 0.74]\n",
      " [0.69 0.9  0.88]\n",
      " [0.9  0.95 0.93]\n",
      " ...\n",
      " [0.59 0.71 0.65]\n",
      " [0.68 0.78 0.77]\n",
      " [0.77 0.86 0.86]]\n",
      "size: (1000, 3)\n",
      "\n",
      "Labels\n",
      "[0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1\n",
      " 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0\n",
      " 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1\n",
      " 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0\n",
      " 1]\n",
      "size: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# convert these data into 2D numpy array\n",
    "# order: math percentage, reading score percentage, writing score percentage\n",
    "X = np.array([[df['math percentage'][0], \n",
    "              df['reading score percentage'][0], \n",
    "              df['writing score percentage'][0]]], \n",
    "             dtype = 'float')\n",
    "for i in range(1,1000):\n",
    "    X = np.append(X, [[df['math percentage'][i], \n",
    "                  df['reading score percentage'][i], \n",
    "                  df['writing score percentage'][i]]],axis=0)\n",
    "print('feature matrix')\n",
    "print(X)\n",
    "print('size: ' + str(X.shape))\n",
    "print()\n",
    "\n",
    "# Standard = 1, Free/Reduced = 2\n",
    "if(df['lunch'][0] == 'standard'):\n",
    "    first_elem = 0\n",
    "else:\n",
    "    first_elem = 1\n",
    "    \n",
    "y = np.array([first_elem], dtype = 'int')\n",
    "for i in range(1,1000):\n",
    "    if(df['lunch'][i] == 'standard'):\n",
    "        y = np.append(y, 0)\n",
    "    else:\n",
    "        y = np.append(y, 1)\n",
    "print('Labels')\n",
    "print(y)\n",
    "print('size: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c5941ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# where X is all the sample data, y is all the labels\n",
    "# random_state=1 means only random once and rest stay the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) # We can fix the random_state for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2208e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 3)\n",
      "(670,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "553acfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 3)\n",
      "(330,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea08e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.91 0.86 0.84]\n",
      " [0.53 0.66 0.73]\n",
      " [0.8  0.73 0.72]\n",
      " [0.74 0.77 0.73]\n",
      " [0.84 0.83 0.78]\n",
      " [0.81 0.75 0.78]\n",
      " [0.69 0.7  0.63]\n",
      " [0.54 0.61 0.62]\n",
      " [0.87 0.73 0.72]\n",
      " [0.51 0.54 0.41]\n",
      " [0.45 0.47 0.49]\n",
      " [0.3  0.26 0.22]\n",
      " [0.67 0.8  0.81]\n",
      " [0.49 0.65 0.61]\n",
      " [0.85 0.81 0.85]\n",
      " [0.65 0.78 0.82]\n",
      " [0.53 0.52 0.42]\n",
      " [0.55 0.46 0.44]\n",
      " [0.48 0.58 0.54]\n",
      " [0.56 0.65 0.63]\n",
      " [0.79 0.72 0.69]\n",
      " [0.43 0.51 0.54]\n",
      " [0.45 0.73 0.7 ]\n",
      " [0.36 0.53 0.43]\n",
      " [0.8  0.79 0.79]\n",
      " [0.8  0.75 0.77]\n",
      " [0.68 0.74 0.74]\n",
      " [0.4  0.59 0.51]\n",
      " [0.34 0.48 0.41]\n",
      " [0.49 0.58 0.6 ]\n",
      " [0.62 0.61 0.57]\n",
      " [0.71 0.61 0.69]\n",
      " [0.62 0.63 0.56]\n",
      " [0.76 0.71 0.72]\n",
      " [0.84 0.77 0.71]\n",
      " [0.45 0.53 0.55]\n",
      " [0.77 0.78 0.73]\n",
      " [0.69 0.77 0.77]\n",
      " [0.73 0.78 0.74]\n",
      " [0.   0.17 0.1 ]\n",
      " [0.82 0.75 0.77]\n",
      " [0.65 0.66 0.62]\n",
      " [0.67 0.61 0.68]\n",
      " [0.54 0.63 0.67]\n",
      " [0.9  0.87 0.75]\n",
      " [0.59 0.63 0.75]\n",
      " [0.74 0.7  0.69]\n",
      " [0.29 0.29 0.3 ]\n",
      " [0.89 0.88 0.82]\n",
      " [0.75 0.82 0.79]\n",
      " [0.71 0.75 0.7 ]\n",
      " [0.64 0.76 0.74]\n",
      " [0.79 0.79 0.78]\n",
      " [0.48 0.56 0.58]\n",
      " [0.69 0.73 0.73]\n",
      " [0.69 0.74 0.74]\n",
      " [0.88 0.78 0.83]\n",
      " [0.58 0.54 0.52]\n",
      " [0.87 0.85 0.73]\n",
      " [0.85 0.9  0.92]\n",
      " [0.46 0.41 0.43]\n",
      " [0.71 0.84 0.87]\n",
      " [0.81 0.77 0.79]\n",
      " [0.58 0.61 0.66]\n",
      " [0.84 0.89 0.9 ]\n",
      " [0.66 0.74 0.81]\n",
      " [0.55 0.71 0.69]\n",
      " [0.59 0.53 0.52]\n",
      " [0.58 0.63 0.73]\n",
      " [0.82 0.95 0.89]\n",
      " [0.66 0.63 0.64]\n",
      " [0.81 0.88 0.9 ]\n",
      " [0.58 0.57 0.54]\n",
      " [0.37 0.57 0.56]\n",
      " [0.63 0.6  0.57]\n",
      " [0.77 0.76 0.77]\n",
      " [0.85 0.86 0.98]\n",
      " [0.57 0.56 0.57]\n",
      " [0.48 0.66 0.65]\n",
      " [0.51 0.52 0.44]\n",
      " [0.63 0.61 0.6 ]\n",
      " [0.45 0.37 0.37]\n",
      " [0.83 0.78 0.73]\n",
      " [0.6  0.72 0.74]\n",
      " [0.63 0.71 0.69]\n",
      " [0.62 0.67 0.64]\n",
      " [0.68 0.78 0.77]\n",
      " [0.6  0.7  0.74]\n",
      " [0.77 0.9  0.85]\n",
      " [0.28 0.23 0.19]\n",
      " [0.79 0.81 0.71]\n",
      " [1.   0.92 0.97]\n",
      " [0.69 0.58 0.57]\n",
      " [0.66 0.77 0.7 ]\n",
      " [0.19 0.38 0.32]\n",
      " [0.75 0.68 0.64]\n",
      " [0.6  0.63 0.59]\n",
      " [0.58 0.7  0.67]\n",
      " [0.69 0.8  0.71]\n",
      " [0.56 0.68 0.7 ]\n",
      " [0.73 0.78 0.72]\n",
      " [0.66 0.57 0.52]\n",
      " [0.67 0.57 0.53]\n",
      " [0.64 0.73 0.68]\n",
      " [0.71 0.74 0.64]\n",
      " [0.7  0.65 0.6 ]\n",
      " [0.53 0.45 0.4 ]\n",
      " [0.75 0.81 0.71]\n",
      " [0.68 0.83 0.78]\n",
      " [0.44 0.61 0.52]\n",
      " [0.29 0.41 0.47]\n",
      " [0.71 0.87 0.82]\n",
      " [0.57 0.51 0.54]\n",
      " [0.45 0.59 0.64]\n",
      " [0.76 0.83 0.88]\n",
      " [0.61 0.56 0.55]\n",
      " [0.45 0.52 0.49]\n",
      " [0.55 0.41 0.48]\n",
      " [0.73 0.69 0.68]\n",
      " [0.78 0.77 0.8 ]\n",
      " [0.5  0.67 0.73]\n",
      " [0.62 0.67 0.62]\n",
      " [0.81 0.81 0.84]\n",
      " [0.64 0.79 0.77]\n",
      " [0.64 0.6  0.74]\n",
      " [0.73 0.66 0.62]\n",
      " [0.73 0.75 0.8 ]\n",
      " [0.67 0.74 0.77]\n",
      " [0.61 0.42 0.41]\n",
      " [0.67 0.73 0.68]\n",
      " [0.65 0.82 0.81]\n",
      " [0.8  0.75 0.69]\n",
      " [0.59 0.42 0.41]\n",
      " [0.88 0.99 0.95]\n",
      " [0.62 0.74 0.7 ]\n",
      " [0.33 0.41 0.43]\n",
      " [0.79 0.92 0.89]\n",
      " [0.84 0.83 0.75]\n",
      " [0.73 0.74 0.72]\n",
      " [0.41 0.51 0.48]\n",
      " [0.5  0.56 0.54]\n",
      " [0.58 0.7  0.68]\n",
      " [0.55 0.59 0.59]\n",
      " [0.45 0.48 0.46]\n",
      " [0.88 0.74 0.75]\n",
      " [0.46 0.61 0.55]\n",
      " [0.51 0.31 0.36]\n",
      " [0.75 0.74 0.69]\n",
      " [0.49 0.52 0.51]\n",
      " [0.75 0.86 0.79]\n",
      " [0.74 0.79 0.8 ]\n",
      " [0.61 0.86 0.87]\n",
      " [0.62 0.65 0.58]\n",
      " [0.68 0.63 0.54]\n",
      " [0.78 0.91 0.96]\n",
      " [0.71 0.7  0.76]\n",
      " [0.49 0.57 0.52]\n",
      " [0.59 0.72 0.7 ]\n",
      " [0.79 0.74 0.72]\n",
      " [0.51 0.51 0.54]\n",
      " [0.56 0.79 0.72]\n",
      " [0.76 0.62 0.6 ]\n",
      " [0.69 0.79 0.81]\n",
      " [0.51 0.56 0.53]\n",
      " [0.82 0.82 0.88]\n",
      " [0.73 0.74 0.61]\n",
      " [0.4  0.46 0.5 ]\n",
      " [0.93 0.9  0.83]\n",
      " [0.59 0.64 0.75]\n",
      " [0.73 0.76 0.8 ]\n",
      " [0.85 0.84 0.78]\n",
      " [0.76 0.71 0.67]\n",
      " [0.77 0.89 0.98]\n",
      " [0.67 0.86 0.83]\n",
      " [0.61 0.47 0.56]\n",
      " [0.27 0.34 0.32]\n",
      " [0.54 0.52 0.52]\n",
      " [0.65 0.81 0.81]\n",
      " [0.87 0.94 0.95]\n",
      " [0.7  0.82 0.76]\n",
      " [0.54 0.64 0.68]\n",
      " [0.66 0.76 0.68]\n",
      " [0.85 0.95 1.  ]\n",
      " [0.56 0.61 0.6 ]\n",
      " [0.9  0.85 0.84]\n",
      " [0.7  0.55 0.56]\n",
      " [0.61 0.72 0.7 ]\n",
      " [0.49 0.58 0.6 ]\n",
      " [0.81 0.66 0.64]\n",
      " [0.87 0.84 0.86]\n",
      " [0.49 0.5  0.52]\n",
      " [0.68 0.54 0.53]\n",
      " [0.77 0.67 0.64]\n",
      " [0.78 0.79 0.76]\n",
      " [0.6  0.51 0.56]\n",
      " [0.52 0.57 0.56]\n",
      " [0.62 0.56 0.53]\n",
      " [0.74 0.81 0.76]\n",
      " [0.65 0.77 0.74]\n",
      " [0.61 0.74 0.72]\n",
      " [0.62 0.7  0.75]\n",
      " [0.66 0.83 0.83]\n",
      " [0.79 0.89 0.86]\n",
      " [0.61 0.67 0.66]\n",
      " [0.73 0.64 0.57]\n",
      " [0.3  0.24 0.15]\n",
      " [0.96 1.   1.  ]\n",
      " [0.57 0.77 0.8 ]\n",
      " [0.68 0.64 0.66]\n",
      " [0.48 0.58 0.52]\n",
      " [0.67 0.64 0.61]\n",
      " [0.59 0.62 0.64]\n",
      " [0.74 0.64 0.6 ]\n",
      " [0.65 0.69 0.76]\n",
      " [0.62 0.67 0.67]\n",
      " [0.47 0.37 0.35]\n",
      " [0.8  0.63 0.63]\n",
      " [0.68 0.6  0.53]\n",
      " [0.79 0.84 0.91]\n",
      " [0.89 0.87 0.79]\n",
      " [0.69 0.67 0.69]\n",
      " [0.53 0.58 0.57]\n",
      " [0.64 0.82 0.77]\n",
      " [0.82 0.84 0.82]\n",
      " [0.36 0.29 0.27]\n",
      " [0.9  0.95 0.93]\n",
      " [0.64 0.63 0.66]\n",
      " [0.52 0.65 0.69]\n",
      " [0.67 0.84 0.84]\n",
      " [0.51 0.6  0.58]\n",
      " [0.79 0.73 0.67]\n",
      " [0.63 0.63 0.62]\n",
      " [0.52 0.59 0.56]\n",
      " [0.4  0.55 0.53]\n",
      " [0.4  0.42 0.38]\n",
      " [0.63 0.65 0.61]\n",
      " [0.46 0.43 0.42]\n",
      " [0.65 0.76 0.75]\n",
      " [0.62 0.64 0.66]\n",
      " [0.9  0.78 0.81]\n",
      " [0.47 0.57 0.44]\n",
      " [0.59 0.41 0.42]\n",
      " [0.77 0.97 0.94]\n",
      " [0.52 0.55 0.57]\n",
      " [0.99 0.87 0.81]\n",
      " [0.7  0.64 0.72]\n",
      " [0.64 0.66 0.59]\n",
      " [0.8  0.78 0.81]\n",
      " [0.42 0.39 0.34]\n",
      " [0.97 0.82 0.88]\n",
      " [0.5  0.47 0.54]\n",
      " [0.65 0.82 0.78]\n",
      " [0.52 0.65 0.61]\n",
      " [0.59 0.62 0.69]\n",
      " [0.74 0.63 0.57]\n",
      " [0.43 0.53 0.53]\n",
      " [0.67 0.78 0.79]\n",
      " [1.   1.   1.  ]\n",
      " [0.72 0.66 0.66]\n",
      " [0.71 0.83 0.78]\n",
      " [0.55 0.46 0.43]\n",
      " [0.84 0.87 0.91]\n",
      " [0.63 0.72 0.7 ]\n",
      " [0.63 0.75 0.81]\n",
      " [0.42 0.66 0.69]\n",
      " [0.78 0.74 0.72]\n",
      " [0.69 0.6  0.54]\n",
      " [0.8  0.86 0.83]\n",
      " [0.79 0.6  0.65]\n",
      " [0.87 1.   0.95]\n",
      " [0.65 0.85 0.76]\n",
      " [0.51 0.63 0.61]\n",
      " [0.85 0.84 0.89]\n",
      " [0.47 0.49 0.49]\n",
      " [0.54 0.59 0.5 ]\n",
      " [0.38 0.6  0.5 ]\n",
      " [0.59 0.69 0.65]\n",
      " [0.6  0.57 0.51]\n",
      " [0.49 0.45 0.45]\n",
      " [0.52 0.59 0.62]\n",
      " [0.44 0.63 0.62]\n",
      " [0.7  0.84 0.81]\n",
      " [0.84 0.8  0.8 ]\n",
      " [0.76 0.7  0.68]\n",
      " [0.35 0.28 0.27]\n",
      " [0.96 0.96 0.99]\n",
      " [0.8  0.9  0.89]\n",
      " [0.81 0.73 0.72]\n",
      " [0.57 0.5  0.54]\n",
      " [0.94 0.73 0.71]\n",
      " [0.82 0.82 0.8 ]\n",
      " [0.7  0.7  0.7 ]\n",
      " [0.94 0.87 0.92]\n",
      " [0.75 0.58 0.62]\n",
      " [0.52 0.58 0.58]\n",
      " [0.77 0.88 0.85]\n",
      " [0.7  0.63 0.58]\n",
      " [0.65 0.59 0.53]\n",
      " [0.4  0.43 0.39]\n",
      " [0.7  0.89 0.88]\n",
      " [0.79 0.82 0.8 ]\n",
      " [0.67 0.81 0.79]\n",
      " [0.68 0.68 0.61]\n",
      " [0.47 0.58 0.67]\n",
      " [0.72 0.79 0.82]\n",
      " [0.57 0.75 0.73]\n",
      " [0.83 0.93 0.95]\n",
      " [0.61 0.51 0.52]\n",
      " [0.98 0.87 0.9 ]\n",
      " [0.61 0.71 0.78]\n",
      " [0.92 1.   0.99]\n",
      " [0.68 0.67 0.73]\n",
      " [0.77 0.79 0.8 ]\n",
      " [0.66 0.59 0.52]\n",
      " [0.47 0.46 0.42]\n",
      " [0.65 0.58 0.49]\n",
      " [0.68 0.72 0.64]\n",
      " [0.63 0.78 0.8 ]\n",
      " [0.73 0.92 0.84]\n",
      " [0.42 0.62 0.6 ]\n",
      " [0.62 0.68 0.68]\n",
      " [0.68 0.75 0.81]\n",
      " [0.67 0.84 0.81]\n",
      " [0.49 0.57 0.46]\n",
      " [0.35 0.44 0.43]\n",
      " [0.68 0.7  0.66]\n",
      " [0.69 0.76 0.74]\n",
      " [0.7  0.74 0.71]\n",
      " [0.8  0.85 0.85]\n",
      " [0.75 0.81 0.84]]\n",
      "\n",
      "\n",
      "[0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1\n",
      " 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58e4775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=0.6181818181818182\n",
      "k=2, accuracy=0.6424242424242425\n",
      "k=3, accuracy=0.6545454545454545\n",
      "k=4, accuracy=0.6454545454545455\n",
      "k=5, accuracy=0.6454545454545455\n",
      "k=6, accuracy=0.6454545454545455\n",
      "k=7, accuracy=0.6545454545454545\n",
      "k=8, accuracy=0.6757575757575758\n",
      "k=9, accuracy=0.6727272727272727\n",
      "k=10, accuracy=0.6818181818181818\n",
      "k=11, accuracy=0.6727272727272727\n",
      "k=12, accuracy=0.6606060606060606\n",
      "k=13, accuracy=0.6818181818181818\n",
      "k=14, accuracy=0.6848484848484848\n",
      "k=15, accuracy=0.6909090909090909\n",
      "k=16, accuracy=0.693939393939394\n",
      "k=17, accuracy=0.6787878787878788\n",
      "k=18, accuracy=0.6696969696969697\n",
      "k=19, accuracy=0.6848484848484848\n",
      "k=20, accuracy=0.6787878787878788\n",
      "k=21, accuracy=0.6848484848484848\n",
      "k=22, accuracy=0.6757575757575758\n",
      "k=23, accuracy=0.6848484848484848\n",
      "k=24, accuracy=0.6878787878787879\n",
      "k=25, accuracy=0.696969696969697\n",
      "k=26, accuracy=0.6878787878787879\n",
      "k=27, accuracy=0.703030303030303\n",
      "k=28, accuracy=0.7\n",
      "k=29, accuracy=0.703030303030303\n",
      "k=30, accuracy=0.696969696969697\n",
      "k=31, accuracy=0.703030303030303\n",
      "k=32, accuracy=0.7\n",
      "k=33, accuracy=0.7\n",
      "k=34, accuracy=0.696969696969697\n",
      "k=35, accuracy=0.7\n",
      "k=36, accuracy=0.696969696969697\n",
      "k=37, accuracy=0.706060606060606\n",
      "k=38, accuracy=0.7121212121212122\n",
      "k=39, accuracy=0.7090909090909091\n",
      "k=40, accuracy=0.7151515151515152\n",
      "k=41, accuracy=0.7151515151515152\n",
      "k=42, accuracy=0.7121212121212122\n",
      "k=43, accuracy=0.703030303030303\n",
      "k=44, accuracy=0.7\n",
      "k=45, accuracy=0.703030303030303\n",
      "k=46, accuracy=0.696969696969697\n",
      "k=47, accuracy=0.7090909090909091\n",
      "k=48, accuracy=0.7\n",
      "k=49, accuracy=0.706060606060606\n",
      "k=50, accuracy=0.7\n",
      "k=51, accuracy=0.7090909090909091\n",
      "k=52, accuracy=0.7\n",
      "k=53, accuracy=0.703030303030303\n",
      "k=54, accuracy=0.7\n",
      "k=55, accuracy=0.7\n",
      "k=56, accuracy=0.696969696969697\n",
      "k=57, accuracy=0.693939393939394\n",
      "k=58, accuracy=0.693939393939394\n",
      "k=59, accuracy=0.696969696969697\n",
      "k=60, accuracy=0.696969696969697\n",
      "k=61, accuracy=0.6909090909090909\n",
      "k=62, accuracy=0.693939393939394\n",
      "k=63, accuracy=0.7\n",
      "k=64, accuracy=0.693939393939394\n",
      "k=65, accuracy=0.696969696969697\n",
      "k=66, accuracy=0.696969696969697\n",
      "k=67, accuracy=0.7\n",
      "k=68, accuracy=0.6909090909090909\n",
      "k=69, accuracy=0.7\n",
      "k=70, accuracy=0.6878787878787879\n",
      "k=71, accuracy=0.693939393939394\n",
      "k=72, accuracy=0.696969696969697\n",
      "k=73, accuracy=0.693939393939394\n",
      "k=74, accuracy=0.706060606060606\n",
      "k=75, accuracy=0.7090909090909091\n",
      "k=76, accuracy=0.7090909090909091\n",
      "k=77, accuracy=0.7090909090909091\n",
      "k=78, accuracy=0.703030303030303\n",
      "k=79, accuracy=0.7090909090909091\n",
      "k=80, accuracy=0.693939393939394\n",
      "k=81, accuracy=0.696969696969697\n",
      "k=82, accuracy=0.693939393939394\n",
      "k=83, accuracy=0.693939393939394\n",
      "k=84, accuracy=0.6818181818181818\n",
      "k=85, accuracy=0.6787878787878788\n",
      "k=86, accuracy=0.6787878787878788\n",
      "k=87, accuracy=0.6878787878787879\n",
      "k=88, accuracy=0.6818181818181818\n",
      "k=89, accuracy=0.6909090909090909\n",
      "k=90, accuracy=0.6878787878787879\n",
      "k=91, accuracy=0.6909090909090909\n",
      "k=92, accuracy=0.6787878787878788\n",
      "k=93, accuracy=0.693939393939394\n",
      "k=94, accuracy=0.696969696969697\n",
      "k=95, accuracy=0.696969696969697\n",
      "k=96, accuracy=0.693939393939394\n",
      "k=97, accuracy=0.693939393939394\n",
      "k=98, accuracy=0.693939393939394\n",
      "k=99, accuracy=0.7\n",
      "k=100, accuracy=0.696969696969697\n",
      "k=101, accuracy=0.696969696969697\n",
      "k=102, accuracy=0.6878787878787879\n",
      "k=103, accuracy=0.6848484848484848\n",
      "k=104, accuracy=0.6818181818181818\n",
      "k=105, accuracy=0.6909090909090909\n",
      "k=106, accuracy=0.6818181818181818\n",
      "k=107, accuracy=0.6818181818181818\n",
      "k=108, accuracy=0.6818181818181818\n",
      "k=109, accuracy=0.6818181818181818\n",
      "k=110, accuracy=0.6818181818181818\n",
      "k=111, accuracy=0.6909090909090909\n",
      "k=112, accuracy=0.6818181818181818\n",
      "k=113, accuracy=0.6818181818181818\n",
      "k=114, accuracy=0.6878787878787879\n",
      "k=115, accuracy=0.6848484848484848\n",
      "k=116, accuracy=0.6818181818181818\n",
      "k=117, accuracy=0.6878787878787879\n",
      "k=118, accuracy=0.6818181818181818\n",
      "k=119, accuracy=0.6787878787878788\n",
      "k=120, accuracy=0.6787878787878788\n",
      "k=121, accuracy=0.6818181818181818\n",
      "k=122, accuracy=0.6818181818181818\n",
      "k=123, accuracy=0.6818181818181818\n",
      "k=124, accuracy=0.6818181818181818\n",
      "k=125, accuracy=0.6757575757575758\n",
      "k=126, accuracy=0.6666666666666666\n",
      "k=127, accuracy=0.6757575757575758\n",
      "k=128, accuracy=0.6696969696969697\n",
      "k=129, accuracy=0.6787878787878788\n",
      "k=130, accuracy=0.6757575757575758\n",
      "k=131, accuracy=0.6787878787878788\n",
      "k=132, accuracy=0.6787878787878788\n",
      "k=133, accuracy=0.6818181818181818\n",
      "k=134, accuracy=0.6757575757575758\n",
      "k=135, accuracy=0.6757575757575758\n",
      "k=136, accuracy=0.6757575757575758\n",
      "k=137, accuracy=0.6757575757575758\n",
      "k=138, accuracy=0.6757575757575758\n",
      "k=139, accuracy=0.6727272727272727\n",
      "k=140, accuracy=0.6575757575757576\n",
      "k=141, accuracy=0.6575757575757576\n",
      "k=142, accuracy=0.6515151515151515\n",
      "k=143, accuracy=0.6575757575757576\n",
      "k=144, accuracy=0.6545454545454545\n",
      "k=145, accuracy=0.6575757575757576\n",
      "k=146, accuracy=0.6484848484848484\n",
      "k=147, accuracy=0.6545454545454545\n",
      "k=148, accuracy=0.6575757575757576\n",
      "k=149, accuracy=0.6575757575757576\n",
      "k=150, accuracy=0.6575757575757576\n",
      "k=151, accuracy=0.6545454545454545\n",
      "k=152, accuracy=0.6606060606060606\n",
      "k=153, accuracy=0.6666666666666666\n",
      "k=154, accuracy=0.6666666666666666\n",
      "k=155, accuracy=0.6696969696969697\n",
      "k=156, accuracy=0.6606060606060606\n",
      "k=157, accuracy=0.6636363636363637\n",
      "k=158, accuracy=0.6545454545454545\n",
      "k=159, accuracy=0.6636363636363637\n",
      "k=160, accuracy=0.6606060606060606\n",
      "k=161, accuracy=0.6666666666666666\n",
      "k=162, accuracy=0.6636363636363637\n",
      "k=163, accuracy=0.6727272727272727\n",
      "k=164, accuracy=0.6666666666666666\n",
      "k=165, accuracy=0.6666666666666666\n",
      "k=166, accuracy=0.6636363636363637\n",
      "k=167, accuracy=0.6666666666666666\n",
      "k=168, accuracy=0.6696969696969697\n",
      "k=169, accuracy=0.6666666666666666\n",
      "k=170, accuracy=0.6666666666666666\n",
      "k=171, accuracy=0.6636363636363637\n",
      "k=172, accuracy=0.6636363636363637\n",
      "k=173, accuracy=0.6606060606060606\n",
      "k=174, accuracy=0.6636363636363637\n",
      "k=175, accuracy=0.6636363636363637\n",
      "k=176, accuracy=0.6666666666666666\n",
      "k=177, accuracy=0.6666666666666666\n",
      "k=178, accuracy=0.6636363636363637\n",
      "k=179, accuracy=0.6636363636363637\n",
      "k=180, accuracy=0.6606060606060606\n",
      "k=181, accuracy=0.6606060606060606\n",
      "k=182, accuracy=0.6606060606060606\n",
      "k=183, accuracy=0.6606060606060606\n",
      "k=184, accuracy=0.6666666666666666\n",
      "k=185, accuracy=0.6636363636363637\n",
      "k=186, accuracy=0.6636363636363637\n",
      "k=187, accuracy=0.6636363636363637\n",
      "k=188, accuracy=0.6636363636363637\n",
      "k=189, accuracy=0.6636363636363637\n",
      "k=190, accuracy=0.6575757575757576\n",
      "k=191, accuracy=0.6575757575757576\n",
      "k=192, accuracy=0.6545454545454545\n",
      "k=193, accuracy=0.6606060606060606\n",
      "k=194, accuracy=0.6545454545454545\n",
      "k=195, accuracy=0.6545454545454545\n",
      "k=196, accuracy=0.6515151515151515\n",
      "k=197, accuracy=0.6636363636363637\n",
      "k=198, accuracy=0.6515151515151515\n",
      "k=199, accuracy=0.6575757575757576\n",
      "k=200, accuracy=0.6545454545454545\n",
      "k=201, accuracy=0.6606060606060606\n",
      "k=202, accuracy=0.6484848484848484\n",
      "k=203, accuracy=0.6515151515151515\n",
      "k=204, accuracy=0.6515151515151515\n",
      "k=205, accuracy=0.6484848484848484\n",
      "k=206, accuracy=0.6484848484848484\n",
      "k=207, accuracy=0.6484848484848484\n",
      "k=208, accuracy=0.6484848484848484\n",
      "k=209, accuracy=0.6484848484848484\n",
      "k=210, accuracy=0.6393939393939394\n",
      "k=211, accuracy=0.6424242424242425\n",
      "k=212, accuracy=0.6333333333333333\n",
      "k=213, accuracy=0.6393939393939394\n",
      "k=214, accuracy=0.6272727272727273\n",
      "k=215, accuracy=0.6363636363636364\n",
      "k=216, accuracy=0.6242424242424243\n",
      "k=217, accuracy=0.6242424242424243\n",
      "k=218, accuracy=0.6272727272727273\n",
      "k=219, accuracy=0.6272727272727273\n",
      "k=220, accuracy=0.6242424242424243\n",
      "k=221, accuracy=0.6272727272727273\n",
      "k=222, accuracy=0.6212121212121212\n",
      "k=223, accuracy=0.6242424242424243\n",
      "k=224, accuracy=0.6212121212121212\n",
      "k=225, accuracy=0.6212121212121212\n",
      "k=226, accuracy=0.6212121212121212\n",
      "k=227, accuracy=0.6212121212121212\n",
      "k=228, accuracy=0.6212121212121212\n",
      "k=229, accuracy=0.6212121212121212\n",
      "k=230, accuracy=0.6212121212121212\n",
      "k=231, accuracy=0.6212121212121212\n",
      "k=232, accuracy=0.6212121212121212\n",
      "k=233, accuracy=0.6212121212121212\n",
      "k=234, accuracy=0.6212121212121212\n",
      "k=235, accuracy=0.6212121212121212\n",
      "k=236, accuracy=0.6212121212121212\n",
      "k=237, accuracy=0.6212121212121212\n",
      "k=238, accuracy=0.6212121212121212\n",
      "k=239, accuracy=0.6212121212121212\n",
      "k=240, accuracy=0.6212121212121212\n",
      "k=241, accuracy=0.6212121212121212\n",
      "k=242, accuracy=0.6212121212121212\n",
      "k=243, accuracy=0.6212121212121212\n",
      "k=244, accuracy=0.6212121212121212\n",
      "k=245, accuracy=0.6212121212121212\n",
      "k=246, accuracy=0.6212121212121212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=247, accuracy=0.6212121212121212\n",
      "k=248, accuracy=0.6212121212121212\n",
      "k=249, accuracy=0.6212121212121212\n",
      "k=250, accuracy=0.6212121212121212\n",
      "k=251, accuracy=0.6212121212121212\n",
      "k=252, accuracy=0.6212121212121212\n",
      "k=253, accuracy=0.6212121212121212\n",
      "k=254, accuracy=0.6212121212121212\n",
      "k=255, accuracy=0.6212121212121212\n",
      "k=256, accuracy=0.6212121212121212\n",
      "k=257, accuracy=0.6212121212121212\n",
      "k=258, accuracy=0.6212121212121212\n",
      "k=259, accuracy=0.6212121212121212\n",
      "k=260, accuracy=0.6212121212121212\n",
      "k=261, accuracy=0.6212121212121212\n",
      "k=262, accuracy=0.6212121212121212\n",
      "k=263, accuracy=0.6212121212121212\n",
      "k=264, accuracy=0.6212121212121212\n",
      "k=265, accuracy=0.6212121212121212\n",
      "k=266, accuracy=0.6212121212121212\n",
      "k=267, accuracy=0.6212121212121212\n",
      "k=268, accuracy=0.6212121212121212\n",
      "k=269, accuracy=0.6212121212121212\n",
      "k=270, accuracy=0.6212121212121212\n",
      "k=271, accuracy=0.6212121212121212\n",
      "k=272, accuracy=0.6212121212121212\n",
      "k=273, accuracy=0.6212121212121212\n",
      "k=274, accuracy=0.6212121212121212\n",
      "k=275, accuracy=0.6212121212121212\n",
      "k=276, accuracy=0.6212121212121212\n",
      "k=277, accuracy=0.6212121212121212\n",
      "k=278, accuracy=0.6212121212121212\n",
      "k=279, accuracy=0.6212121212121212\n",
      "k=280, accuracy=0.6212121212121212\n",
      "k=281, accuracy=0.6212121212121212\n",
      "k=282, accuracy=0.6212121212121212\n",
      "k=283, accuracy=0.6212121212121212\n",
      "k=284, accuracy=0.6212121212121212\n",
      "k=285, accuracy=0.6212121212121212\n",
      "k=286, accuracy=0.6212121212121212\n",
      "k=287, accuracy=0.6212121212121212\n",
      "k=288, accuracy=0.6212121212121212\n",
      "k=289, accuracy=0.6212121212121212\n",
      "k=290, accuracy=0.6212121212121212\n",
      "k=291, accuracy=0.6212121212121212\n",
      "k=292, accuracy=0.6212121212121212\n",
      "k=293, accuracy=0.6212121212121212\n",
      "k=294, accuracy=0.6212121212121212\n",
      "k=295, accuracy=0.6212121212121212\n",
      "k=296, accuracy=0.6212121212121212\n",
      "k=297, accuracy=0.6212121212121212\n",
      "k=298, accuracy=0.6212121212121212\n",
      "k=299, accuracy=0.6212121212121212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(1,300):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    print('k=' + str(i) + ', accuracy=' + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
