{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908eb19a",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd08d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Student Performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321aa56",
   "metadata": {},
   "source": [
    "## Obtain label features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265dee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix\n",
      "[[0.72 0.72 0.74]\n",
      " [0.69 0.9  0.88]\n",
      " [0.9  0.95 0.93]\n",
      " ...\n",
      " [0.59 0.71 0.65]\n",
      " [0.68 0.78 0.77]\n",
      " [0.77 0.86 0.86]]\n",
      "size: (1000, 3)\n",
      "\n",
      "Labels\n",
      "[1 3 0 2 3 2 3 3 4 4 2 2 4 3 0 5 4 5 0 2 4 3 3 5 1 0 3 1 4 0 3 3 0 3 3 2 2\n",
      " 5 2 2 2 2 2 3 2 2 2 4 2 4 3 2 3 4 5 4 2 2 3 5 1 5 2 2 5 5 5 3 2 2 3 3 2 5\n",
      " 5 2 5 1 5 0 2 4 3 2 4 3 3 2 3 5 1 4 4 2 3 2 5 3 3 1 3 1 2 4 3 3 0 2 2 5 2\n",
      " 4 2 3 1 4 1 1 5 3 1 2 3 4 3 4 5 3 0 1 0 5 3 3 1 1 5 4 2 3 5 3 3 4 3 3 5 2\n",
      " 1 2 5 1 2 1 5 3 4 3 2 2 2 3 0 4 0 1 4 0 4 3 4 5 3 2 1 0 4 2 0 5 0 3 4 2 5\n",
      " 2 4 5 5 1 2 3 5 3 0 2 5 4 3 1 2 3 2 2 3 5 1 4 3 3 5 3 4 2 4 5 2 4 4 5 4 2\n",
      " 5 5 2 0 3 4 5 3 3 2 1 5 1 2 1 5 3 2 4 1 4 3 5 2 2 4 4 4 5 3 5 0 4 3 2 2 3\n",
      " 0 5 3 5 4 4 5 1 4 2 3 1 3 2 3 3 1 5 4 5 1 4 4 1 3 5 2 2 5 1 5 2 5 5 1 4 2\n",
      " 5 2 4 2 3 5 2 2 2 3 3 5 2 4 2 1 1 2 1 4 0 2 1 2 4 4 3 5 4 3 3 3 2 5 4 2 2\n",
      " 2 1 3 5 2 5 5 4 4 4 2 3 4 3 1 4 2 1 3 3 2 3 1 2 3 3 3 4 5 3 5 3 1 4 1 5 5\n",
      " 3 3 5 3 1 2 5 0 5 1 2 2 0 5 5 3 1 2 4 0 5 3 3 2 5 4 4 2 5 5 5 3 3 4 4 5 2\n",
      " 2 4 2 0 3 2 5 1 4 1 2 3 4 2 4 0 5 3 3 1 5 5 5 2 4 4 5 5 3 2 2 4 5 3 4 5 2\n",
      " 5 5 3 4 4 2 3 3 2 3 2 1 1 2 1 4 1 3 3 3 1 3 2 4 4 3 2 4 2 5 2 1 1 2 0 2 4\n",
      " 2 3 4 2 4 3 2 5 2 2 2 3 1 4 4 3 3 5 3 0 2 3 2 0 5 4 1 0 1 3 5 5 5 0 5 3 3\n",
      " 5 4 3 2 1 0 4 3 5 4 1 2 2 5 2 2 4 1 2 4 1 2 4 2 2 2 0 5 5 4 4 0 5 1 2 3 2\n",
      " 3 2 0 2 5 3 3 1 3 1 2 1 0 4 1 3 1 3 4 4 2 3 4 3 0 5 5 1 2 3 2 4 1 3 5 3 5\n",
      " 1 4 1 1 4 5 4 5 0 4 3 4 0 5 2 0 3 2 3 3 1 2 2 4 1 1 0 2 4 1 4 3 1 3 2 2 3\n",
      " 5 3 4 1 4 5 4 4 5 3 2 4 2 5 4 4 1 2 4 4 3 5 4 3 2 5 3 2 5 2 2 3 5 3 4 2 5\n",
      " 3 1 3 2 4 2 3 2 4 3 3 5 2 3 4 4 4 5 3 0 3 2 4 3 2 2 1 2 5 3 2 1 2 4 1 5 1\n",
      " 3 5 1 4 3 4 2 3 5 3 0 5 2 2 2 4 2 3 5 5 4 3 3 2 5 4 3 2 5 3 5 3 0 2 3 2 4\n",
      " 1 2 4 2 3 2 4 3 1 3 5 3 0 5 2 2 3 1 3 3 4 5 5 4 3 4 4 4 5 3 4 1 5 1 3 5 4\n",
      " 3 3 2 2 0 4 2 1 5 5 3 2 0 4 3 4 5 4 2 4 2 3 2 5 5 2 3 3 3 3 4 4 1 5 4 0 5\n",
      " 4 5 1 1 4 5 5 1 3 4 5 4 2 5 5 5 3 1 1 4 3 4 4 4 2 2 4 5 4 3 5 0 0 4 4 2 0\n",
      " 4 3 5 5 1 3 1 4 2 2 0 1 3 2 3 4 2 2 2 4 3 2 2 1 3 3 5 5 2 1 1 4 1 2 2 2 4\n",
      " 3 4 3 2 0 5 2 5 4 5 2 5 0 0 4 1 5 3 4 3 1 1 1 3 1 1 2 3 1 4 2 3 4 4 4 2 4\n",
      " 5 2 4 2 5 3 3 2 1 2 3 2 4 3 5 0 0 4 5 4 2 4 3 5 4 4 3 5 4 3 2 3 0 4 4 3 5\n",
      " 2 5 3 3 5 3 2 1 1 5 4 3 3 3 3 2 4 2 4 5 5 3 5 4 2 5 5 3 4 5 2 1 4 0 4 4 3\n",
      " 3]\n",
      "size: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# convert these data into 2D numpy array\n",
    "# order: math percentage, reading score percentage, writing score percentage\n",
    "X = np.array([[df['math percentage'][0], \n",
    "              df['reading score percentage'][0], \n",
    "              df['writing score percentage'][0]]], \n",
    "             dtype = 'float')\n",
    "for i in range(1,1000):\n",
    "    X = np.append(X, [[df['math percentage'][i], \n",
    "                  df['reading score percentage'][i], \n",
    "                  df['writing score percentage'][i]]],axis=0)\n",
    "print('feature matrix')\n",
    "print(X)\n",
    "print('size: ' + str(X.shape))\n",
    "print()\n",
    "\n",
    "# lavel 0: master's degree\n",
    "if(df['parental level of education'][0] == \"master's degree\"):\n",
    "    first_elem = 0\n",
    "# lavel 1: bachelor's degree\n",
    "elif(df['parental level of education'][0] == \"bachelor's degree\"):\n",
    "    first_elem = 1\n",
    "# lavel 2: associate's degree\n",
    "elif(df['parental level of education'][0] == \"associate's degree\"):\n",
    "    first_elem = 2\n",
    "# lavel 3: some college\n",
    "elif(df['parental level of education'][0] == 'some college'):\n",
    "    first_elem = 3\n",
    "# lavel 4: high school\n",
    "elif(df['parental level of education'][0] == 'high school'):\n",
    "    first_elem = 4\n",
    "# lavel 5: some high school\n",
    "else:\n",
    "    first_elem = 5\n",
    "    \n",
    "y = np.array([first_elem], dtype = 'int')\n",
    "for i in range(1,1000):\n",
    "    if(df['parental level of education'][i] == \"master's degree\"):\n",
    "        y = np.append(y, 0)\n",
    "    elif(df['parental level of education'][i] == \"bachelor's degree\"):\n",
    "        y = np.append(y, 1)\n",
    "    elif(df['parental level of education'][i] == \"associate's degree\"):\n",
    "        y = np.append(y, 2)\n",
    "    elif(df['parental level of education'][i] == 'some college'):\n",
    "        y = np.append(y, 3)\n",
    "    elif(df['parental level of education'][i] == 'high school'):\n",
    "        y = np.append(y, 4)\n",
    "    else:\n",
    "        y = np.append(y, 5)\n",
    "print('Labels')\n",
    "print(y)\n",
    "print('size: ' + str(y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7c3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08815ffa",
   "metadata": {},
   "source": [
    "## Use sklearn functions to split the dataset into testing and training sets with the following parameters: test_size=0.3, random_state=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a1c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc39ce",
   "metadata": {},
   "source": [
    " ## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621a36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=57)\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "clf4 = RandomForestClassifier(n_estimators=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f512b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier (estimators= [('KNN', clf1), ('lr', clf2), ('dt', clf3), ('rf', clf4)], voting = 'hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ebc00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier (estimators= [('KNN', clf1), ('lr', clf2), ('dt', clf3), ('rf', clf4)], voting = 'soft')\n",
    "eclf2 = eclf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe53122",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f190f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbd2001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2733333333333333\n"
     ]
    }
   ],
   "source": [
    "y_predict = eclf1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9458cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25666666666666665\n"
     ]
    }
   ],
   "source": [
    "y_predict = eclf2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2acab",
   "metadata": {},
   "source": [
    "#### Using BootStrap with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9848d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2733333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bootstarp_size = int(np.floor( 0.8 * len(X_train) ))\n",
    "accuracy_list = list()\n",
    "\n",
    "for i in range(0, 19):\n",
    "    \n",
    "    # Step1 (Bootstrapping)\n",
    "    X_bag = resample(X_train, n_samples = bootstarp_size , random_state=i , replace = True)\n",
    "    y_bag = resample(y_train, n_samples = bootstarp_size , random_state=i , replace = True)\n",
    "    \n",
    "    # Step2 (Training)\n",
    "    Base_DecisionTree = DecisionTreeClassifier(random_state=3)\n",
    "    Base_DecisionTree.fit(X_bag, y_bag)\n",
    "\n",
    "    Base_logreg = LogisticRegression(max_iter=150)\n",
    "    Base_logreg.fit(X_bag, y_bag)\n",
    "\n",
    "    Base_knn = KNeighborsClassifier(n_neighbors=57)\n",
    "    Base_knn.fit(X_bag, y_bag)\n",
    "\n",
    "    Base_rf = RandomForestClassifier(n_estimators=19)\n",
    "    Base_rf.fit(X_bag, y_bag)\n",
    "        \n",
    "    Base_eclf1 = VotingClassifier (estimators= [('dt', Base_DecisionTree), ('lr', Base_logreg), ('KNN', Base_knn), ('rf', Base_rf)], voting = 'hard')\n",
    "    Base_eclf1 = Base_eclf1.fit(X_bag, y_bag)\n",
    "    \n",
    "    Base_eclf2 = VotingClassifier (estimators= [('dt', Base_DecisionTree), ('lr', Base_logreg), ('KNN', Base_knn), ('rf', Base_rf)], voting = 'soft')\n",
    "    Base_eclf2 = Base_eclf1.fit(X_bag, y_bag)\n",
    "    \n",
    "    # Step3 (Base Learner Prediction)\n",
    "    y_predict1 = Base_DecisionTree.predict(X_test)\n",
    "    y_predict2 = Base_logreg.predict(X_test)\n",
    "    y_predict3 = Base_knn.predict(X_test)\n",
    "    y_predict4 = Base_rf.predict(X_test)\n",
    "    y_predict5 = Base_eclf1.predict(X_test)\n",
    "    y_predict6 = Base_eclf2.predict(X_test)\n",
    "    \n",
    "    accuracy1 = accuracy_score(y_test, y_predict1)\n",
    "    accuracy2 = accuracy_score(y_test, y_predict2)\n",
    "    accuracy3 = accuracy_score(y_test, y_predict3)\n",
    "    accuracy4 = accuracy_score(y_test, y_predict4)\n",
    "    accuracy5 = accuracy_score(y_test, y_predict5)\n",
    "    accuracy6 = accuracy_score(y_test, y_predict6)\n",
    "\n",
    "    # Step4 (Voting)\n",
    "    curr_acc_list = [accuracy1, accuracy2, accuracy3, accuracy4, accuracy5, accuracy6]\n",
    "    accuracy_list.append(max(curr_acc_list))\n",
    "print(max(accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95686778",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ff8940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6357142857142858\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "bootstarp_size = int(np.floor( 0.8 * len(X_train) ))\n",
    "final_accuracy_list = list()\n",
    "\n",
    "for i in range(0, 19):\n",
    "    \n",
    "    # Step1 (Bootstrapping)\n",
    "    X_bag = resample(X_train, n_samples = bootstarp_size , random_state=i , replace = True)\n",
    "    y_bag = resample(y_train, n_samples = bootstarp_size , random_state=i , replace = True)\n",
    "    \n",
    "    # Step2 (Training)\n",
    "    Base_DecisionTree = DecisionTreeClassifier(random_state=3)\n",
    "\n",
    "    Base_logreg = LogisticRegression(max_iter=150)\n",
    "\n",
    "    Base_knn = KNeighborsClassifier(n_neighbors=164)\n",
    "\n",
    "    Base_rf = RandomForestClassifier(n_estimators=19)\n",
    "        \n",
    "    Base_eclf1 = VotingClassifier (estimators= [('dt', Base_DecisionTree), ('lr', Base_logreg), ('KNN', Base_knn), ('rf', Base_rf)], voting = 'hard')\n",
    "    \n",
    "    Base_eclf2 = VotingClassifier (estimators= [('dt', Base_DecisionTree), ('lr', Base_logreg), ('KNN', Base_knn), ('rf', Base_rf)], voting = 'soft')\n",
    "        \n",
    "    # Step3 (Base Learner Prediction)\n",
    "    accuracy_list1 = cross_val_score(Base_DecisionTree, X_bag, y_bag, cv=10, scoring='accuracy')\n",
    "    accuracy_list2 = cross_val_score(Base_logreg, X_bag, y_bag, cv=10, scoring='accuracy')\n",
    "    accuracy_list3 = cross_val_score(Base_knn, X_bag, y_bag, cv=10, scoring='accuracy')\n",
    "    accuracy_list4 = cross_val_score(Base_rf, X_bag, y_bag, cv=10, scoring='accuracy')\n",
    "    accuracy_list5 = cross_val_score(Base_eclf1, X_bag, y_bag, cv=10, scoring='accuracy')\n",
    "    accuracy_list6 = cross_val_score(Base_eclf2, X_bag, y_bag, cv=10, scoring='accuracy')\n",
    "    \n",
    "    accuracy_cv1 = accuracy_list1.mean()\n",
    "    accuracy_cv2 = accuracy_list2.mean()\n",
    "    accuracy_cv3 = accuracy_list3.mean()\n",
    "    accuracy_cv4 = accuracy_list4.mean()\n",
    "    accuracy_cv5 = accuracy_list5.mean()\n",
    "    accuracy_cv6 = accuracy_list6.mean()\n",
    "        \n",
    "    # Step4 (Voting)\n",
    "    curr_max_acc = [accuracy_cv1, accuracy_cv2, accuracy_cv3, accuracy_cv4, accuracy_cv5, accuracy_cv6]\n",
    "    final_accuracy_list.append(max(curr_max_acc))\n",
    "    \n",
    "print(max(final_accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac1034",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Model accuracy: 0.64 with Cross Validation\n",
    "### Model accuracy: 0.28 without Cross Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
